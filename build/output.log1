[src/hash_table.c:270] Insert attempt - Key: key1
[src/hash_table.c:272] Current state - Size: 0, Capacity: 10
[src/hash_table.c:274] Load factor: 0.000000
[src/hash_table.c:270] Insert attempt - Key: key1
[src/hash_table.c:272] Current state - Size: 1, Capacity: 10
[src/hash_table.c:274] Load factor: 0.100000

Testing free_hash_table memory management...
Hash table created: 0x204ba330
[src/hash_table.c:270] Insert attempt - Key: key1
[src/hash_table.c:272] Current state - Size: 0, Capacity: 10
[src/hash_table.c:274] Load factor: 0.000000
[src/hash_table.c:270] Insert attempt - Key: key2
[src/hash_table.c:272] Current state - Size: 1, Capacity: 10
[src/hash_table.c:274] Load factor: 0.100000
Inserted entries into hash table.
Hash table successfully freed.
[src/tokenizer.c:71] Allocating tokenizer structure at 0x204c2370
[src/tokenizer.c:73] Allocating vocabulary with initial size 10 
[src/tokenizer.c:92] 
Error: Could not tokenize dataset or zero token
[src/tokenizer.c:514] Freeing the Vocabulary itself 0x204ba500
[src/tokenizer.c:71] Allocating tokenizer structure at 0x204c2370
[src/tokenizer.c:73] Allocating vocabulary with initial size 10 
[src/tokenizer.c:92] 
[src/tokenizer.c:676] Token created: 0x204bcc00, text: a
[src/tokenizer.c:676] Token created: 0x204bcc40, text: 
[src/tokenizer.c:676] Token created: 0x204bcc80, text: b
[src/tokenizer.c:676] Token created: 0x204bccc0, text: 
[src/tokenizer.c:676] Token created: 0x204bcd00, text: c
[src/tokenizer.c:676] Token created: 0x204bcd40, text: 
[src/tokenizer.c:676] Token created: 0x204bcda0, text: d
[src/tokenizer.c:676] Token created: 0x204bcde0, text: 

[src/tokenizer.c:676] Token created: 0x204bce20, text: 
Error while reading line in the textfile.
[src/tokenizer.c:839] 
Initial tokens: 9
[src/tokenizer.c:842] Initializing Vocabulary...[src/tokenizer.c:676] Token created: 0x204be360, text: a
[src/tokenizer.c:676] Token created: 0x204be3a0, text: 
[src/tokenizer.c:676] Token created: 0x204be3e0, text: b
[src/tokenizer.c:676] Token created: 0x204be420, text: 
[src/tokenizer.c:676] Token created: 0x204be460, text: c
[src/tokenizer.c:676] Token created: 0x204be4a0, text: 
[src/tokenizer.c:676] Token created: 0x204be500, text: d
[src/tokenizer.c:676] Token created: 0x204be540, text: 

[src/tokenizer.c:676] Token created: 0x204be580, text: 
Error while reading line in the textfile.
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:676] Token created: 0x204be5a0, text: a
[src/tokenizer.c:140] New Token created Text: a Frequency: 1.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be360
[src/tokenizer.c:690] Token freed: 0x204be360 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:676] Token created: 0x204be5c0, text: 
[src/tokenizer.c:140] New Token created Text:  Frequency: 1.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be3a0
[src/tokenizer.c:690] Token freed: 0x204be3a0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:676] Token created: 0x204be600, text: b
[src/tokenizer.c:140] New Token created Text: b Frequency: 1.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be3e0
[src/tokenizer.c:690] Token freed: 0x204be3e0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be420
[src/tokenizer.c:690] Token freed: 0x204be420 
[src/tokenizer.c:540] Adding token c to vocabulary.[src/tokenizer.c:676] Token created: 0x204be670, text: c
[src/tokenizer.c:140] New Token created Text: c Frequency: 1.
[src/tokenizer.c:544] Token c added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be460
[src/tokenizer.c:690] Token freed: 0x204be460 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be4a0
[src/tokenizer.c:690] Token freed: 0x204be4a0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:676] Token created: 0x204be6c0, text: d
[src/tokenizer.c:140] New Token created Text: d Frequency: 1.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be500
[src/tokenizer.c:690] Token freed: 0x204be500 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:676] Token created: 0x204be710, text: 

[src/tokenizer.c:140] New Token created Text: 
 Frequency: 1.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be540
[src/tokenizer.c:690] Token freed: 0x204be540 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204be580
[src/tokenizer.c:690] Token freed: 0x204be580 
[src/tokenizer.c:846] Vocabulary initialized.[src/tokenizer.c:849] Counting pairs...
No entry in hash table.
[src/tokenizer.c:686] Token text freed: 0x204bcc00
[src/tokenizer.c:690] Token freed: 0x204bcc00 
[src/tokenizer.c:686] Token text freed: 0x204bcc40
[src/tokenizer.c:690] Token freed: 0x204bcc40 
[src/tokenizer.c:686] Token text freed: 0x204bcc80
[src/tokenizer.c:690] Token freed: 0x204bcc80 
[src/tokenizer.c:686] Token text freed: 0x204bccc0
[src/tokenizer.c:690] Token freed: 0x204bccc0 
[src/tokenizer.c:686] Token text freed: 0x204bcd00
[src/tokenizer.c:690] Token freed: 0x204bcd00 
[src/tokenizer.c:686] Token text freed: 0x204bcd40
[src/tokenizer.c:690] Token freed: 0x204bcd40 
[src/tokenizer.c:686] Token text freed: 0x204bcda0
[src/tokenizer.c:690] Token freed: 0x204bcda0 
[src/tokenizer.c:686] Token text freed: 0x204bcde0
[src/tokenizer.c:690] Token freed: 0x204bcde0 
[src/tokenizer.c:686] Token text freed: 0x204bce20
[src/tokenizer.c:690] Token freed: 0x204bce20 
[src/tokenizer.c:505] Freeing the vocabulary at 0 
[src/tokenizer.c:686] Token text freed: 0x204be5c0
[src/tokenizer.c:690] Token freed: 0x204be5c0 
[src/tokenizer.c:505] Freeing the vocabulary at 3 
[src/tokenizer.c:686] Token text freed: 0x204be710
[src/tokenizer.c:690] Token freed: 0x204be710 
[src/tokenizer.c:505] Freeing the vocabulary at 4 
[src/tokenizer.c:686] Token text freed: 0x204be670
[src/tokenizer.c:690] Token freed: 0x204be670 
[src/tokenizer.c:505] Freeing the vocabulary at 5 
[src/tokenizer.c:686] Token text freed: 0x204be5a0
[src/tokenizer.c:690] Token freed: 0x204be5a0 
[src/tokenizer.c:505] Freeing the vocabulary at 6 
[src/tokenizer.c:686] Token text freed: 0x204be600
[src/tokenizer.c:690] Token freed: 0x204be600 
[src/tokenizer.c:505] Freeing the vocabulary at 7 
[src/tokenizer.c:686] Token text freed: 0x204be6c0
[src/tokenizer.c:690] Token freed: 0x204be6c0 
[src/tokenizer.c:514] Freeing the Vocabulary itself 0x204ba460
[src/tokenizer.c:71] Allocating tokenizer structure at 0x204c2370
[src/tokenizer.c:73] Allocating vocabulary with initial size 200000 
[src/tokenizer.c:92] 
[src/tokenizer.c:676] Token created: 0x204ca4f0, text: c
[src/tokenizer.c:676] Token created: 0x204baf40, text: a
[src/tokenizer.c:676] Token created: 0x204baf60, text: t
[src/tokenizer.c:676] Token created: 0x204baf80, text: 
[src/tokenizer.c:676] Token created: 0x204be5a0, text: d
[src/tokenizer.c:676] Token created: 0x204be5c0, text: o
[src/tokenizer.c:676] Token created: 0x204be5e0, text: g
[src/tokenizer.c:676] Token created: 0x204be600, text: 
[src/tokenizer.c:676] Token created: 0x204bae10, text: b
[src/tokenizer.c:676] Token created: 0x204bae50, text: i
[src/tokenizer.c:676] Token created: 0x204be380, text: r
[src/tokenizer.c:676] Token created: 0x204be3c0, text: d
[src/tokenizer.c:676] Token created: 0x204be460, text: 
[src/tokenizer.c:676] Token created: 0x204be480, text: d
[src/tokenizer.c:676] Token created: 0x204be4c0, text: o
[src/tokenizer.c:676] Token created: 0x204be500, text: g
[src/tokenizer.c:676] Token created: 0x204bcc40, text: 
[src/tokenizer.c:676] Token created: 0x204bcc80, text: c
[src/tokenizer.c:676] Token created: 0x204bccc0, text: a
[src/tokenizer.c:676] Token created: 0x204bcd00, text: t
[src/tokenizer.c:676] Token created: 0x204bcd40, text: 
[src/tokenizer.c:676] Token created: 0x204bce00, text: b
[src/tokenizer.c:676] Token created: 0x204bea90, text: i
[src/tokenizer.c:676] Token created: 0x204bead0, text: r
[src/tokenizer.c:676] Token created: 0x204beb10, text: d
[src/tokenizer.c:676] Token created: 0x204beb50, text: 

[src/tokenizer.c:676] Token created: 0x204beb90, text: 
[src/tokenizer.c:676] Token created: 0x204bec10, text: a
[src/tokenizer.c:676] Token created: 0x204bec50, text: p
[src/tokenizer.c:676] Token created: 0x204bec90, text: p
[src/tokenizer.c:676] Token created: 0x204becd0, text: l
[src/tokenizer.c:676] Token created: 0x204bed10, text: e
[src/tokenizer.c:676] Token created: 0x204bed50, text: 
[src/tokenizer.c:676] Token created: 0x204bedb0, text: o
[src/tokenizer.c:676] Token created: 0x204bedf0, text: r
[src/tokenizer.c:676] Token created: 0x204bee30, text: a
[src/tokenizer.c:676] Token created: 0x204bee70, text: n
[src/tokenizer.c:676] Token created: 0x204beeb0, text: g
[src/tokenizer.c:676] Token created: 0x204beef0, text: e
[src/tokenizer.c:676] Token created: 0x204bef30, text: 
[src/tokenizer.c:676] Token created: 0x204bef70, text: b
[src/tokenizer.c:676] Token created: 0x204befb0, text: a
[src/tokenizer.c:676] Token created: 0x204beff0, text: n
[src/tokenizer.c:676] Token created: 0x204bf030, text: a
[src/tokenizer.c:676] Token created: 0x204bf070, text: n
[src/tokenizer.c:676] Token created: 0x204bf0b0, text: a
[src/tokenizer.c:676] Token created: 0x204bf0f0, text: 
[src/tokenizer.c:676] Token created: 0x204bf110, text: a
[src/tokenizer.c:676] Token created: 0x204bf150, text: p
[src/tokenizer.c:676] Token created: 0x204bf190, text: p
[src/tokenizer.c:676] Token created: 0x204bf1d0, text: l
[src/tokenizer.c:676] Token created: 0x204bf210, text: e
[src/tokenizer.c:676] Token created: 0x204bf250, text: 
[src/tokenizer.c:676] Token created: 0x204bf2b0, text: o
[src/tokenizer.c:676] Token created: 0x204bf2f0, text: r
[src/tokenizer.c:676] Token created: 0x204bf330, text: a
[src/tokenizer.c:676] Token created: 0x204bf370, text: n
[src/tokenizer.c:676] Token created: 0x204bf3b0, text: g
[src/tokenizer.c:676] Token created: 0x204bf3f0, text: e
[src/tokenizer.c:676] Token created: 0x204bf430, text: 
[src/tokenizer.c:676] Token created: 0x204bf4e0, text: b
[src/tokenizer.c:676] Token created: 0x204bf520, text: a
[src/tokenizer.c:676] Token created: 0x204bf560, text: n
[src/tokenizer.c:676] Token created: 0x204bf5a0, text: a
[src/tokenizer.c:676] Token created: 0x204bf5e0, text: n
[src/tokenizer.c:676] Token created: 0x204bf620, text: a
[src/tokenizer.c:676] Token created: 0x204bf660, text: 

[src/tokenizer.c:676] Token created: 0x204bf6a0, text: 
[src/tokenizer.c:676] Token created: 0x204bf6c0, text: b
[src/tokenizer.c:676] Token created: 0x204bf6e0, text: l
[src/tokenizer.c:676] Token created: 0x204bf700, text: u
[src/tokenizer.c:676] Token created: 0x204bf740, text: e
[src/tokenizer.c:676] Token created: 0x204bf780, text: 
[src/tokenizer.c:676] Token created: 0x204bf7a0, text: r
[src/tokenizer.c:676] Token created: 0x204bf7e0, text: e
[src/tokenizer.c:676] Token created: 0x204bf820, text: d
[src/tokenizer.c:676] Token created: 0x204bf860, text: 
[src/tokenizer.c:676] Token created: 0x204bf8e0, text: g
[src/tokenizer.c:676] Token created: 0x204bf920, text: r
[src/tokenizer.c:676] Token created: 0x204bf960, text: e
[src/tokenizer.c:676] Token created: 0x204bf9a0, text: e
[src/tokenizer.c:676] Token created: 0x204bf9e0, text: n
[src/tokenizer.c:676] Token created: 0x204bfa20, text: 
[src/tokenizer.c:676] Token created: 0x204bfa40, text: b
[src/tokenizer.c:676] Token created: 0x204bfa80, text: l
[src/tokenizer.c:676] Token created: 0x204bfac0, text: u
[src/tokenizer.c:676] Token created: 0x204bfb00, text: e
[src/tokenizer.c:676] Token created: 0x204bfb40, text: 
[src/tokenizer.c:676] Token created: 0x204bfb60, text: r
[src/tokenizer.c:676] Token created: 0x204bfba0, text: e
[src/tokenizer.c:676] Token created: 0x204bfbe0, text: d
[src/tokenizer.c:676] Token created: 0x204bfc20, text: 
[src/tokenizer.c:676] Token created: 0x204bfcc0, text: g
[src/tokenizer.c:676] Token created: 0x204bfd00, text: r
[src/tokenizer.c:676] Token created: 0x204bfd40, text: e
[src/tokenizer.c:676] Token created: 0x204bfd80, text: e
[src/tokenizer.c:676] Token created: 0x204bfdc0, text: n
[src/tokenizer.c:676] Token created: 0x204bfe00, text: 

[src/tokenizer.c:676] Token created: 0x204bfe40, text: 
[src/tokenizer.c:676] Token created: 0x204bfe60, text: h
[src/tokenizer.c:676] Token created: 0x204bfea0, text: a
[src/tokenizer.c:676] Token created: 0x204c0530, text: p
[src/tokenizer.c:676] Token created: 0x204c0570, text: p
[src/tokenizer.c:676] Token created: 0x204c05b0, text: y
[src/tokenizer.c:676] Token created: 0x204c05f0, text: 
[src/tokenizer.c:676] Token created: 0x204c0610, text: s
[src/tokenizer.c:676] Token created: 0x204c0630, text: a
[src/tokenizer.c:676] Token created: 0x204c0670, text: d
[src/tokenizer.c:676] Token created: 0x204c06b0, text: 
[src/tokenizer.c:676] Token created: 0x204c0750, text: j
[src/tokenizer.c:676] Token created: 0x204c0790, text: o
[src/tokenizer.c:676] Token created: 0x204c07d0, text: y
[src/tokenizer.c:676] Token created: 0x204c0810, text: f
[src/tokenizer.c:676] Token created: 0x204c0850, text: u
[src/tokenizer.c:676] Token created: 0x204c0890, text: l
[src/tokenizer.c:676] Token created: 0x204c08d0, text: 
[src/tokenizer.c:676] Token created: 0x204c08f0, text: h
[src/tokenizer.c:676] Token created: 0x204c0930, text: a
[src/tokenizer.c:676] Token created: 0x204c0970, text: p
[src/tokenizer.c:676] Token created: 0x204c09b0, text: p
[src/tokenizer.c:676] Token created: 0x204c09f0, text: y
[src/tokenizer.c:676] Token created: 0x204c0a30, text: 
[src/tokenizer.c:676] Token created: 0x204c0a50, text: s
[src/tokenizer.c:676] Token created: 0x204c0a70, text: a
[src/tokenizer.c:676] Token created: 0x204c0ab0, text: d
[src/tokenizer.c:676] Token created: 0x204c0af0, text: 
[src/tokenizer.c:676] Token created: 0x204c0bb0, text: j
[src/tokenizer.c:676] Token created: 0x204c0bf0, text: o
[src/tokenizer.c:676] Token created: 0x204c0c30, text: y
[src/tokenizer.c:676] Token created: 0x204c0c70, text: f
[src/tokenizer.c:676] Token created: 0x204c0cb0, text: u
[src/tokenizer.c:676] Token created: 0x204c0cf0, text: l
[src/tokenizer.c:676] Token created: 0x204c0d30, text: 

[src/tokenizer.c:676] Token created: 0x204c0d70, text: 
[src/tokenizer.c:676] Token created: 0x204c0d90, text: d
[src/tokenizer.c:676] Token created: 0x204c0db0, text: o
[src/tokenizer.c:676] Token created: 0x204c0dd0, text: g
[src/tokenizer.c:676] Token created: 0x204c0df0, text: 
[src/tokenizer.c:676] Token created: 0x204c0e70, text: a
[src/tokenizer.c:676] Token created: 0x204c0eb0, text: p
[src/tokenizer.c:676] Token created: 0x204c0ef0, text: p
[src/tokenizer.c:676] Token created: 0x204c0f30, text: l
[src/tokenizer.c:676] Token created: 0x204c0f70, text: e
[src/tokenizer.c:676] Token created: 0x204c0fb0, text: 
[src/tokenizer.c:676] Token created: 0x204c0fd0, text: c
[src/tokenizer.c:676] Token created: 0x204c0ff0, text: a
[src/tokenizer.c:676] Token created: 0x204c1030, text: t
[src/tokenizer.c:676] Token created: 0x204c1070, text: 
[src/tokenizer.c:676] Token created: 0x204c1110, text: o
[src/tokenizer.c:676] Token created: 0x204c1150, text: r
[src/tokenizer.c:676] Token created: 0x204c1190, text: a
[src/tokenizer.c:676] Token created: 0x204c11d0, text: n
[src/tokenizer.c:676] Token created: 0x204c1210, text: g
[src/tokenizer.c:676] Token created: 0x204c1250, text: e
[src/tokenizer.c:676] Token created: 0x204c1290, text: 
[src/tokenizer.c:676] Token created: 0x204c12b0, text: b
[src/tokenizer.c:676] Token created: 0x204c12d0, text: i
[src/tokenizer.c:676] Token created: 0x204c1310, text: r
[src/tokenizer.c:676] Token created: 0x204c1350, text: d
[src/tokenizer.c:676] Token created: 0x204c1390, text: 
[src/tokenizer.c:676] Token created: 0x204c1430, text: b
[src/tokenizer.c:676] Token created: 0x204c1470, text: a
[src/tokenizer.c:676] Token created: 0x204c14b0, text: n
[src/tokenizer.c:676] Token created: 0x204c14f0, text: a
[src/tokenizer.c:676] Token created: 0x204c1530, text: n
[src/tokenizer.c:676] Token created: 0x204c1570, text: a
[src/tokenizer.c:676] Token created: 0x204c15b0, text: 

[src/tokenizer.c:676] Token created: 0x204c15f0, text: 
Error while reading line in the textfile.
[src/tokenizer.c:839] 
Initial tokens: 168
[src/tokenizer.c:842] Initializing Vocabulary...[src/tokenizer.c:676] Token created: 0x204c1b20, text: c
[src/tokenizer.c:676] Token created: 0x204c1b40, text: a
[src/tokenizer.c:676] Token created: 0x204c1b60, text: t
[src/tokenizer.c:676] Token created: 0x204c1b80, text: 
[src/tokenizer.c:676] Token created: 0x204c1bc0, text: d
[src/tokenizer.c:676] Token created: 0x204c1c00, text: o
[src/tokenizer.c:676] Token created: 0x204c1c40, text: g
[src/tokenizer.c:676] Token created: 0x204c1c80, text: 
[src/tokenizer.c:676] Token created: 0x204c1ce0, text: b
[src/tokenizer.c:676] Token created: 0x204c1d20, text: i
[src/tokenizer.c:676] Token created: 0x204c1d60, text: r
[src/tokenizer.c:676] Token created: 0x204c1da0, text: d
[src/tokenizer.c:676] Token created: 0x204c1de0, text: 
[src/tokenizer.c:676] Token created: 0x204c1e00, text: d
[src/tokenizer.c:676] Token created: 0x204c1e40, text: o
[src/tokenizer.c:676] Token created: 0x204c1e80, text: g
[src/tokenizer.c:676] Token created: 0x204c1ec0, text: 
[src/tokenizer.c:676] Token created: 0x204c1f00, text: c
[src/tokenizer.c:676] Token created: 0x204c1f40, text: a
[src/tokenizer.c:676] Token created: 0x204c1f80, text: t
[src/tokenizer.c:676] Token created: 0x204c1fc0, text: 
[src/tokenizer.c:676] Token created: 0x204c2040, text: b
[src/tokenizer.c:676] Token created: 0x204c2080, text: i
[src/tokenizer.c:676] Token created: 0x204c20c0, text: r
[src/tokenizer.c:676] Token created: 0x204c2100, text: d
[src/tokenizer.c:676] Token created: 0x204c2140, text: 

[src/tokenizer.c:676] Token created: 0x204c2180, text: 
[src/tokenizer.c:676] Token created: 0x204c21c0, text: a
[src/tokenizer.c:676] Token created: 0x204c2200, text: p
[src/tokenizer.c:676] Token created: 0x204c2240, text: p
[src/tokenizer.c:676] Token created: 0x204c2280, text: l
[src/tokenizer.c:676] Token created: 0x204c22c0, text: e
[src/tokenizer.c:676] Token created: 0x204c2300, text: 
[src/tokenizer.c:676] Token created: 0x204c3410, text: o
[src/tokenizer.c:676] Token created: 0x204c3450, text: r
[src/tokenizer.c:676] Token created: 0x204c3490, text: a
[src/tokenizer.c:676] Token created: 0x204c34d0, text: n
[src/tokenizer.c:676] Token created: 0x204c3510, text: g
[src/tokenizer.c:676] Token created: 0x204c3550, text: e
[src/tokenizer.c:676] Token created: 0x204c3590, text: 
[src/tokenizer.c:676] Token created: 0x204c35f0, text: b
[src/tokenizer.c:676] Token created: 0x204c3630, text: a
[src/tokenizer.c:676] Token created: 0x204c3670, text: n
[src/tokenizer.c:676] Token created: 0x204c36b0, text: a
[src/tokenizer.c:676] Token created: 0x204c36f0, text: n
[src/tokenizer.c:676] Token created: 0x204c3730, text: a
[src/tokenizer.c:676] Token created: 0x204c3770, text: 
[src/tokenizer.c:676] Token created: 0x204c3790, text: a
[src/tokenizer.c:676] Token created: 0x204c37d0, text: p
[src/tokenizer.c:676] Token created: 0x204c3810, text: p
[src/tokenizer.c:676] Token created: 0x204c3850, text: l
[src/tokenizer.c:676] Token created: 0x204c3890, text: e
[src/tokenizer.c:676] Token created: 0x204c38d0, text: 
[src/tokenizer.c:676] Token created: 0x204c3930, text: o
[src/tokenizer.c:676] Token created: 0x204c3970, text: r
[src/tokenizer.c:676] Token created: 0x204c39b0, text: a
[src/tokenizer.c:676] Token created: 0x204c39f0, text: n
[src/tokenizer.c:676] Token created: 0x204c3a30, text: g
[src/tokenizer.c:676] Token created: 0x204c3a70, text: e
[src/tokenizer.c:676] Token created: 0x204c3ab0, text: 
[src/tokenizer.c:676] Token created: 0x204c3b10, text: b
[src/tokenizer.c:676] Token created: 0x204c3b50, text: a
[src/tokenizer.c:676] Token created: 0x204c3b90, text: n
[src/tokenizer.c:676] Token created: 0x204c3bd0, text: a
[src/tokenizer.c:676] Token created: 0x204c3c10, text: n
[src/tokenizer.c:676] Token created: 0x204c3c50, text: a
[src/tokenizer.c:676] Token created: 0x204c3c90, text: 

[src/tokenizer.c:676] Token created: 0x204c3cd0, text: 
[src/tokenizer.c:676] Token created: 0x204c3cf0, text: b
[src/tokenizer.c:676] Token created: 0x204c3d10, text: l
[src/tokenizer.c:676] Token created: 0x204c3d30, text: u
[src/tokenizer.c:676] Token created: 0x204c3d70, text: e
[src/tokenizer.c:676] Token created: 0x204c3db0, text: 
[src/tokenizer.c:676] Token created: 0x204c3dd0, text: r
[src/tokenizer.c:676] Token created: 0x204c3e10, text: e
[src/tokenizer.c:676] Token created: 0x204c3e50, text: d
[src/tokenizer.c:676] Token created: 0x204c3e90, text: 
[src/tokenizer.c:676] Token created: 0x204c3f10, text: g
[src/tokenizer.c:676] Token created: 0x204c3f50, text: r
[src/tokenizer.c:676] Token created: 0x204c3f90, text: e
[src/tokenizer.c:676] Token created: 0x204c3fd0, text: e
[src/tokenizer.c:676] Token created: 0x204c4010, text: n
[src/tokenizer.c:676] Token created: 0x204c4050, text: 
[src/tokenizer.c:676] Token created: 0x204c4070, text: b
[src/tokenizer.c:676] Token created: 0x204c40b0, text: l
[src/tokenizer.c:676] Token created: 0x204c40f0, text: u
[src/tokenizer.c:676] Token created: 0x204c4130, text: e
[src/tokenizer.c:676] Token created: 0x204c4170, text: 
[src/tokenizer.c:676] Token created: 0x204c4190, text: r
[src/tokenizer.c:676] Token created: 0x204c41d0, text: e
[src/tokenizer.c:676] Token created: 0x204c4210, text: d
[src/tokenizer.c:676] Token created: 0x204c4250, text: 
[src/tokenizer.c:676] Token created: 0x204c42f0, text: g
[src/tokenizer.c:676] Token created: 0x204c4330, text: r
[src/tokenizer.c:676] Token created: 0x204c4370, text: e
[src/tokenizer.c:676] Token created: 0x204c43b0, text: e
[src/tokenizer.c:676] Token created: 0x204c43f0, text: n
[src/tokenizer.c:676] Token created: 0x204c4430, text: 

[src/tokenizer.c:676] Token created: 0x204c4470, text: 
[src/tokenizer.c:676] Token created: 0x204c4490, text: h
[src/tokenizer.c:676] Token created: 0x204c44d0, text: a
[src/tokenizer.c:676] Token created: 0x204c4b60, text: p
[src/tokenizer.c:676] Token created: 0x204c4ba0, text: p
[src/tokenizer.c:676] Token created: 0x204c4be0, text: y
[src/tokenizer.c:676] Token created: 0x204c4c20, text: 
[src/tokenizer.c:676] Token created: 0x204c4c40, text: s
[src/tokenizer.c:676] Token created: 0x204c4c60, text: a
[src/tokenizer.c:676] Token created: 0x204c4ca0, text: d
[src/tokenizer.c:676] Token created: 0x204c4ce0, text: 
[src/tokenizer.c:676] Token created: 0x204c4d80, text: j
[src/tokenizer.c:676] Token created: 0x204c4dc0, text: o
[src/tokenizer.c:676] Token created: 0x204c4e00, text: y
[src/tokenizer.c:676] Token created: 0x204c4e40, text: f
[src/tokenizer.c:676] Token created: 0x204c4e80, text: u
[src/tokenizer.c:676] Token created: 0x204c4ec0, text: l
[src/tokenizer.c:676] Token created: 0x204c4f00, text: 
[src/tokenizer.c:676] Token created: 0x204c4f20, text: h
[src/tokenizer.c:676] Token created: 0x204c4f60, text: a
[src/tokenizer.c:676] Token created: 0x204c4fa0, text: p
[src/tokenizer.c:676] Token created: 0x204c4fe0, text: p
[src/tokenizer.c:676] Token created: 0x204c5020, text: y
[src/tokenizer.c:676] Token created: 0x204c5060, text: 
[src/tokenizer.c:676] Token created: 0x204c5080, text: s
[src/tokenizer.c:676] Token created: 0x204c50a0, text: a
[src/tokenizer.c:676] Token created: 0x204c50e0, text: d
[src/tokenizer.c:676] Token created: 0x204c5120, text: 
[src/tokenizer.c:676] Token created: 0x204c51e0, text: j
[src/tokenizer.c:676] Token created: 0x204c5220, text: o
[src/tokenizer.c:676] Token created: 0x204c5260, text: y
[src/tokenizer.c:676] Token created: 0x204c52a0, text: f
[src/tokenizer.c:676] Token created: 0x204c52e0, text: u
[src/tokenizer.c:676] Token created: 0x204c5320, text: l
[src/tokenizer.c:676] Token created: 0x204c5360, text: 

[src/tokenizer.c:676] Token created: 0x204c53a0, text: 
[src/tokenizer.c:676] Token created: 0x204c53c0, text: d
[src/tokenizer.c:676] Token created: 0x204c53e0, text: o
[src/tokenizer.c:676] Token created: 0x204c5400, text: g
[src/tokenizer.c:676] Token created: 0x204c5420, text: 
[src/tokenizer.c:676] Token created: 0x204c54a0, text: a
[src/tokenizer.c:676] Token created: 0x204c54e0, text: p
[src/tokenizer.c:676] Token created: 0x204c5520, text: p
[src/tokenizer.c:676] Token created: 0x204c5560, text: l
[src/tokenizer.c:676] Token created: 0x204c55a0, text: e
[src/tokenizer.c:676] Token created: 0x204c55e0, text: 
[src/tokenizer.c:676] Token created: 0x204c5600, text: c
[src/tokenizer.c:676] Token created: 0x204c5620, text: a
[src/tokenizer.c:676] Token created: 0x204c5660, text: t
[src/tokenizer.c:676] Token created: 0x204c56a0, text: 
[src/tokenizer.c:676] Token created: 0x204c5740, text: o
[src/tokenizer.c:676] Token created: 0x204c5780, text: r
[src/tokenizer.c:676] Token created: 0x204c57c0, text: a
[src/tokenizer.c:676] Token created: 0x204c5800, text: n
[src/tokenizer.c:676] Token created: 0x204c5840, text: g
[src/tokenizer.c:676] Token created: 0x204c5880, text: e
[src/tokenizer.c:676] Token created: 0x204c58c0, text: 
[src/tokenizer.c:676] Token created: 0x204c58e0, text: b
[src/tokenizer.c:676] Token created: 0x204c5900, text: i
[src/tokenizer.c:676] Token created: 0x204c5940, text: r
[src/tokenizer.c:676] Token created: 0x204c5980, text: d
[src/tokenizer.c:676] Token created: 0x204c59c0, text: 
[src/tokenizer.c:676] Token created: 0x204c5a60, text: b
[src/tokenizer.c:676] Token created: 0x204c5aa0, text: a
[src/tokenizer.c:676] Token created: 0x204c5ae0, text: n
[src/tokenizer.c:676] Token created: 0x204c5b20, text: a
[src/tokenizer.c:676] Token created: 0x204c5b60, text: n
[src/tokenizer.c:676] Token created: 0x204c5ba0, text: a
[src/tokenizer.c:676] Token created: 0x204c5be0, text: 

[src/tokenizer.c:676] Token created: 0x204c5c20, text: 
Error while reading line in the textfile.
[src/tokenizer.c:540] Adding token c to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5c40, text: c
[src/tokenizer.c:140] New Token created Text: c Frequency: 1.
[src/tokenizer.c:544] Token c added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1b20
[src/tokenizer.c:690] Token freed: 0x204c1b20 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5c60, text: a
[src/tokenizer.c:140] New Token created Text: a Frequency: 1.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1b40
[src/tokenizer.c:690] Token freed: 0x204c1b40 
[src/tokenizer.c:540] Adding token t to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5c80, text: t
[src/tokenizer.c:140] New Token created Text: t Frequency: 1.
[src/tokenizer.c:544] Token t added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1b60
[src/tokenizer.c:690] Token freed: 0x204c1b60 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5ca0, text: 
[src/tokenizer.c:140] New Token created Text:  Frequency: 1.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1b80
[src/tokenizer.c:690] Token freed: 0x204c1b80 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5cc0, text: d
[src/tokenizer.c:140] New Token created Text: d Frequency: 1.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1bc0
[src/tokenizer.c:690] Token freed: 0x204c1bc0 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5d00, text: o
[src/tokenizer.c:140] New Token created Text: o Frequency: 1.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1c00
[src/tokenizer.c:690] Token freed: 0x204c1c00 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5d40, text: g
[src/tokenizer.c:140] New Token created Text: g Frequency: 1.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1c40
[src/tokenizer.c:690] Token freed: 0x204c1c40 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1c80
[src/tokenizer.c:690] Token freed: 0x204c1c80 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5d80, text: b
[src/tokenizer.c:140] New Token created Text: b Frequency: 1.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1ce0
[src/tokenizer.c:690] Token freed: 0x204c1ce0 
[src/tokenizer.c:540] Adding token i to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5dd0, text: i
[src/tokenizer.c:140] New Token created Text: i Frequency: 1.
[src/tokenizer.c:544] Token i added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1d20
[src/tokenizer.c:690] Token freed: 0x204c1d20 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:676] Token created: 0x204c5e20, text: r
[src/tokenizer.c:140] New Token created Text: r Frequency: 1.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1d60
[src/tokenizer.c:690] Token freed: 0x204c1d60 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1da0
[src/tokenizer.c:690] Token freed: 0x204c1da0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1de0
[src/tokenizer.c:690] Token freed: 0x204c1de0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1e00
[src/tokenizer.c:690] Token freed: 0x204c1e00 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1e40
[src/tokenizer.c:690] Token freed: 0x204c1e40 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1e80
[src/tokenizer.c:690] Token freed: 0x204c1e80 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1ec0
[src/tokenizer.c:690] Token freed: 0x204c1ec0 
[src/tokenizer.c:540] Adding token c to vocabulary.[src/tokenizer.c:676] Token created: 0x204c1ec0, text: c
[src/tokenizer.c:140] New Token created Text: c Frequency: 1.
[src/tokenizer.c:544] Token c added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1f00
[src/tokenizer.c:690] Token freed: 0x204c1f00 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1f40
[src/tokenizer.c:690] Token freed: 0x204c1f40 
[src/tokenizer.c:540] Adding token t to vocabulary.[src/tokenizer.c:125] Token t already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token t added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1f80
[src/tokenizer.c:690] Token freed: 0x204c1f80 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c1fc0
[src/tokenizer.c:690] Token freed: 0x204c1fc0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2040
[src/tokenizer.c:690] Token freed: 0x204c2040 
[src/tokenizer.c:540] Adding token i to vocabulary.[src/tokenizer.c:125] Token i already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token i added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2080
[src/tokenizer.c:690] Token freed: 0x204c2080 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c20c0
[src/tokenizer.c:690] Token freed: 0x204c20c0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2100
[src/tokenizer.c:690] Token freed: 0x204c2100 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:676] Token created: 0x204c2100, text: 

[src/tokenizer.c:140] New Token created Text: 
 Frequency: 1.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2140
[src/tokenizer.c:690] Token freed: 0x204c2140 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2180
[src/tokenizer.c:690] Token freed: 0x204c2180 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c21c0
[src/tokenizer.c:690] Token freed: 0x204c21c0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:676] Token created: 0x204c21c0, text: p
[src/tokenizer.c:140] New Token created Text: p Frequency: 1.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2200
[src/tokenizer.c:690] Token freed: 0x204c2200 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2240
[src/tokenizer.c:690] Token freed: 0x204c2240 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:676] Token created: 0x204c2240, text: l
[src/tokenizer.c:140] New Token created Text: l Frequency: 1.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2280
[src/tokenizer.c:690] Token freed: 0x204c2280 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:676] Token created: 0x204c21e0, text: e
[src/tokenizer.c:140] New Token created Text: e Frequency: 1.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c22c0
[src/tokenizer.c:690] Token freed: 0x204c22c0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c2300
[src/tokenizer.c:690] Token freed: 0x204c2300 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3410
[src/tokenizer.c:690] Token freed: 0x204c3410 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3450
[src/tokenizer.c:690] Token freed: 0x204c3450 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3490
[src/tokenizer.c:690] Token freed: 0x204c3490 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:676] Token created: 0x204c3490, text: n
[src/tokenizer.c:140] New Token created Text: n Frequency: 1.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c34d0
[src/tokenizer.c:690] Token freed: 0x204c34d0 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3510
[src/tokenizer.c:690] Token freed: 0x204c3510 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3550
[src/tokenizer.c:690] Token freed: 0x204c3550 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3590
[src/tokenizer.c:690] Token freed: 0x204c3590 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c35f0
[src/tokenizer.c:690] Token freed: 0x204c35f0 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3630
[src/tokenizer.c:690] Token freed: 0x204c3630 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3670
[src/tokenizer.c:690] Token freed: 0x204c3670 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c36b0
[src/tokenizer.c:690] Token freed: 0x204c36b0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c36f0
[src/tokenizer.c:690] Token freed: 0x204c36f0 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3730
[src/tokenizer.c:690] Token freed: 0x204c3730 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3770
[src/tokenizer.c:690] Token freed: 0x204c3770 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3790
[src/tokenizer.c:690] Token freed: 0x204c3790 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c37d0
[src/tokenizer.c:690] Token freed: 0x204c37d0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3810
[src/tokenizer.c:690] Token freed: 0x204c3810 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3850
[src/tokenizer.c:690] Token freed: 0x204c3850 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3890
[src/tokenizer.c:690] Token freed: 0x204c3890 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c38d0
[src/tokenizer.c:690] Token freed: 0x204c38d0 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3930
[src/tokenizer.c:690] Token freed: 0x204c3930 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3970
[src/tokenizer.c:690] Token freed: 0x204c3970 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c39b0
[src/tokenizer.c:690] Token freed: 0x204c39b0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c39f0
[src/tokenizer.c:690] Token freed: 0x204c39f0 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3a30
[src/tokenizer.c:690] Token freed: 0x204c3a30 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3a70
[src/tokenizer.c:690] Token freed: 0x204c3a70 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 10.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3ab0
[src/tokenizer.c:690] Token freed: 0x204c3ab0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3b10
[src/tokenizer.c:690] Token freed: 0x204c3b10 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3b50
[src/tokenizer.c:690] Token freed: 0x204c3b50 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3b90
[src/tokenizer.c:690] Token freed: 0x204c3b90 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 10.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3bd0
[src/tokenizer.c:690] Token freed: 0x204c3bd0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3c10
[src/tokenizer.c:690] Token freed: 0x204c3c10 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 11.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3c50
[src/tokenizer.c:690] Token freed: 0x204c3c50 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:125] Token 
 already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3c90
[src/tokenizer.c:690] Token freed: 0x204c3c90 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 11.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3cd0
[src/tokenizer.c:690] Token freed: 0x204c3cd0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3cf0
[src/tokenizer.c:690] Token freed: 0x204c3cf0 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3d10
[src/tokenizer.c:690] Token freed: 0x204c3d10 
[src/tokenizer.c:540] Adding token u to vocabulary.[src/tokenizer.c:676] Token created: 0x204c3d10, text: u
[src/tokenizer.c:140] New Token created Text: u Frequency: 1.
[src/tokenizer.c:544] Token u added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3d30
[src/tokenizer.c:690] Token freed: 0x204c3d30 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3d70
[src/tokenizer.c:690] Token freed: 0x204c3d70 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 12.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3db0
[src/tokenizer.c:690] Token freed: 0x204c3db0 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3dd0
[src/tokenizer.c:690] Token freed: 0x204c3dd0 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3e10
[src/tokenizer.c:690] Token freed: 0x204c3e10 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3e50
[src/tokenizer.c:690] Token freed: 0x204c3e50 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 13.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3e90
[src/tokenizer.c:690] Token freed: 0x204c3e90 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3f10
[src/tokenizer.c:690] Token freed: 0x204c3f10 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3f50
[src/tokenizer.c:690] Token freed: 0x204c3f50 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3f90
[src/tokenizer.c:690] Token freed: 0x204c3f90 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c3fd0
[src/tokenizer.c:690] Token freed: 0x204c3fd0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4010
[src/tokenizer.c:690] Token freed: 0x204c4010 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 14.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4050
[src/tokenizer.c:690] Token freed: 0x204c4050 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4070
[src/tokenizer.c:690] Token freed: 0x204c4070 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c40b0
[src/tokenizer.c:690] Token freed: 0x204c40b0 
[src/tokenizer.c:540] Adding token u to vocabulary.[src/tokenizer.c:125] Token u already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token u added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c40f0
[src/tokenizer.c:690] Token freed: 0x204c40f0 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4130
[src/tokenizer.c:690] Token freed: 0x204c4130 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 15.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4170
[src/tokenizer.c:690] Token freed: 0x204c4170 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4190
[src/tokenizer.c:690] Token freed: 0x204c4190 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4210
[src/tokenizer.c:690] Token freed: 0x204c4210 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 16.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4250
[src/tokenizer.c:690] Token freed: 0x204c4250 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c42f0
[src/tokenizer.c:690] Token freed: 0x204c42f0 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4330
[src/tokenizer.c:690] Token freed: 0x204c4330 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 10.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4370
[src/tokenizer.c:690] Token freed: 0x204c4370 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 11.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c43b0
[src/tokenizer.c:690] Token freed: 0x204c43b0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c43f0
[src/tokenizer.c:690] Token freed: 0x204c43f0 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:125] Token 
 already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4430
[src/tokenizer.c:690] Token freed: 0x204c4430 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 17.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4470
[src/tokenizer.c:690] Token freed: 0x204c4470 
[src/tokenizer.c:540] Adding token h to vocabulary.[src/tokenizer.c:676] Token created: 0x204c4470, text: h
[src/tokenizer.c:140] New Token created Text: h Frequency: 1.
[src/tokenizer.c:544] Token h added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4490
[src/tokenizer.c:690] Token freed: 0x204c4490 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 12.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c44d0
[src/tokenizer.c:690] Token freed: 0x204c44d0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4b60
[src/tokenizer.c:690] Token freed: 0x204c4b60 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4ba0
[src/tokenizer.c:690] Token freed: 0x204c4ba0 
[src/tokenizer.c:540] Adding token y to vocabulary.[src/tokenizer.c:676] Token created: 0x204c4ba0, text: y
[src/tokenizer.c:140] New Token created Text: y Frequency: 1.
[src/tokenizer.c:544] Token y added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4be0
[src/tokenizer.c:690] Token freed: 0x204c4be0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 18.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4c20
[src/tokenizer.c:690] Token freed: 0x204c4c20 
[src/tokenizer.c:540] Adding token s to vocabulary.[src/tokenizer.c:676] Token created: 0x204c4c20, text: s
[src/tokenizer.c:140] New Token created Text: s Frequency: 1.
[src/tokenizer.c:544] Token s added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4c40
[src/tokenizer.c:690] Token freed: 0x204c4c40 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 13.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4c60
[src/tokenizer.c:690] Token freed: 0x204c4c60 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4ca0
[src/tokenizer.c:690] Token freed: 0x204c4ca0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 19.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4ce0
[src/tokenizer.c:690] Token freed: 0x204c4ce0 
[src/tokenizer.c:540] Adding token j to vocabulary.[src/tokenizer.c:676] Token created: 0x204c4ce0, text: j
[src/tokenizer.c:140] New Token created Text: j Frequency: 1.
[src/tokenizer.c:544] Token j added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4d80
[src/tokenizer.c:690] Token freed: 0x204c4d80 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4dc0
[src/tokenizer.c:690] Token freed: 0x204c4dc0 
[src/tokenizer.c:540] Adding token y to vocabulary.[src/tokenizer.c:125] Token y already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token y added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4e00
[src/tokenizer.c:690] Token freed: 0x204c4e00 
[src/tokenizer.c:540] Adding token f to vocabulary.[src/tokenizer.c:676] Token created: 0x204c4e00, text: f
[src/tokenizer.c:140] New Token created Text: f Frequency: 1.
[src/tokenizer.c:544] Token f added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4e40
[src/tokenizer.c:690] Token freed: 0x204c4e40 
[src/tokenizer.c:540] Adding token u to vocabulary.[src/tokenizer.c:125] Token u already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token u added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4e80
[src/tokenizer.c:690] Token freed: 0x204c4e80 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4ec0
[src/tokenizer.c:690] Token freed: 0x204c4ec0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 20.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4f00
[src/tokenizer.c:690] Token freed: 0x204c4f00 
[src/tokenizer.c:540] Adding token h to vocabulary.[src/tokenizer.c:125] Token h already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token h added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4f20
[src/tokenizer.c:690] Token freed: 0x204c4f20 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 14.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4f60
[src/tokenizer.c:690] Token freed: 0x204c4f60 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4fa0
[src/tokenizer.c:690] Token freed: 0x204c4fa0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c4fe0
[src/tokenizer.c:690] Token freed: 0x204c4fe0 
[src/tokenizer.c:540] Adding token y to vocabulary.[src/tokenizer.c:125] Token y already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token y added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5020
[src/tokenizer.c:690] Token freed: 0x204c5020 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 21.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5060
[src/tokenizer.c:690] Token freed: 0x204c5060 
[src/tokenizer.c:540] Adding token s to vocabulary.[src/tokenizer.c:125] Token s already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token s added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5080
[src/tokenizer.c:690] Token freed: 0x204c5080 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 15.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c50a0
[src/tokenizer.c:690] Token freed: 0x204c50a0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c50e0
[src/tokenizer.c:690] Token freed: 0x204c50e0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 22.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5120
[src/tokenizer.c:690] Token freed: 0x204c5120 
[src/tokenizer.c:540] Adding token j to vocabulary.[src/tokenizer.c:125] Token j already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token j added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c51e0
[src/tokenizer.c:690] Token freed: 0x204c51e0 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5220
[src/tokenizer.c:690] Token freed: 0x204c5220 
[src/tokenizer.c:540] Adding token y to vocabulary.[src/tokenizer.c:125] Token y already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token y added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5260
[src/tokenizer.c:690] Token freed: 0x204c5260 
[src/tokenizer.c:540] Adding token f to vocabulary.[src/tokenizer.c:125] Token f already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token f added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c52a0
[src/tokenizer.c:690] Token freed: 0x204c52a0 
[src/tokenizer.c:540] Adding token u to vocabulary.[src/tokenizer.c:125] Token u already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token u added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c52e0
[src/tokenizer.c:690] Token freed: 0x204c52e0 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 5.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5320
[src/tokenizer.c:690] Token freed: 0x204c5320 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:125] Token 
 already in the vocabulary. Frequency: 3.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5360
[src/tokenizer.c:690] Token freed: 0x204c5360 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 23.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c53a0
[src/tokenizer.c:690] Token freed: 0x204c53a0 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c53c0
[src/tokenizer.c:690] Token freed: 0x204c53c0 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c53e0
[src/tokenizer.c:690] Token freed: 0x204c53e0 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5400
[src/tokenizer.c:690] Token freed: 0x204c5400 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 24.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5420
[src/tokenizer.c:690] Token freed: 0x204c5420 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 16.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c54a0
[src/tokenizer.c:690] Token freed: 0x204c54a0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c54e0
[src/tokenizer.c:690] Token freed: 0x204c54e0 
[src/tokenizer.c:540] Adding token p to vocabulary.[src/tokenizer.c:125] Token p already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token p added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5520
[src/tokenizer.c:690] Token freed: 0x204c5520 
[src/tokenizer.c:540] Adding token l to vocabulary.[src/tokenizer.c:125] Token l already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token l added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5560
[src/tokenizer.c:690] Token freed: 0x204c5560 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 12.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c55a0
[src/tokenizer.c:690] Token freed: 0x204c55a0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 25.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c55e0
[src/tokenizer.c:690] Token freed: 0x204c55e0 
[src/tokenizer.c:540] Adding token c to vocabulary.[src/tokenizer.c:125] Token c already in the vocabulary. Frequency: 1.
[src/tokenizer.c:544] Token c added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5600
[src/tokenizer.c:690] Token freed: 0x204c5600 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 17.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5620
[src/tokenizer.c:690] Token freed: 0x204c5620 
[src/tokenizer.c:540] Adding token t to vocabulary.[src/tokenizer.c:125] Token t already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token t added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5660
[src/tokenizer.c:690] Token freed: 0x204c5660 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 26.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c56a0
[src/tokenizer.c:690] Token freed: 0x204c56a0 
[src/tokenizer.c:540] Adding token o to vocabulary.[src/tokenizer.c:125] Token o already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token o added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5740
[src/tokenizer.c:690] Token freed: 0x204c5740 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5780
[src/tokenizer.c:690] Token freed: 0x204c5780 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 18.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c57c0
[src/tokenizer.c:690] Token freed: 0x204c57c0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 8.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5800
[src/tokenizer.c:690] Token freed: 0x204c5800 
[src/tokenizer.c:540] Adding token g to vocabulary.[src/tokenizer.c:125] Token g already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token g added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5840
[src/tokenizer.c:690] Token freed: 0x204c5840 
[src/tokenizer.c:540] Adding token e to vocabulary.[src/tokenizer.c:125] Token e already in the vocabulary. Frequency: 13.
[src/tokenizer.c:544] Token e added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5880
[src/tokenizer.c:690] Token freed: 0x204c5880 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 27.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c58c0
[src/tokenizer.c:690] Token freed: 0x204c58c0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 6.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c58e0
[src/tokenizer.c:690] Token freed: 0x204c58e0 
[src/tokenizer.c:540] Adding token i to vocabulary.[src/tokenizer.c:125] Token i already in the vocabulary. Frequency: 2.
[src/tokenizer.c:544] Token i added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5900
[src/tokenizer.c:690] Token freed: 0x204c5900 
[src/tokenizer.c:540] Adding token r to vocabulary.[src/tokenizer.c:125] Token r already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token r added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5940
[src/tokenizer.c:690] Token freed: 0x204c5940 
[src/tokenizer.c:540] Adding token d to vocabulary.[src/tokenizer.c:125] Token d already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token d added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5980
[src/tokenizer.c:690] Token freed: 0x204c5980 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 28.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c59c0
[src/tokenizer.c:690] Token freed: 0x204c59c0 
[src/tokenizer.c:540] Adding token b to vocabulary.[src/tokenizer.c:125] Token b already in the vocabulary. Frequency: 7.
[src/tokenizer.c:544] Token b added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5a60
[src/tokenizer.c:690] Token freed: 0x204c5a60 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 19.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5aa0
[src/tokenizer.c:690] Token freed: 0x204c5aa0 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 9.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5ae0
[src/tokenizer.c:690] Token freed: 0x204c5ae0 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 20.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5b20
[src/tokenizer.c:690] Token freed: 0x204c5b20 
[src/tokenizer.c:540] Adding token n to vocabulary.[src/tokenizer.c:125] Token n already in the vocabulary. Frequency: 10.
[src/tokenizer.c:544] Token n added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5b60
[src/tokenizer.c:690] Token freed: 0x204c5b60 
[src/tokenizer.c:540] Adding token a to vocabulary.[src/tokenizer.c:125] Token a already in the vocabulary. Frequency: 21.
[src/tokenizer.c:544] Token a added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5ba0
[src/tokenizer.c:690] Token freed: 0x204c5ba0 
[src/tokenizer.c:540] Adding token 
 to vocabulary.[src/tokenizer.c:125] Token 
 already in the vocabulary. Frequency: 4.
[src/tokenizer.c:544] Token 
 added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5be0
[src/tokenizer.c:690] Token freed: 0x204c5be0 
[src/tokenizer.c:540] Adding token  to vocabulary.[src/tokenizer.c:125] Token  already in the vocabulary. Frequency: 29.
[src/tokenizer.c:544] Token  added to vocabulary.
[src/tokenizer.c:686] Token text freed: 0x204c5c20
[src/tokenizer.c:690] Token freed: 0x204c5c20 
[src/tokenizer.c:846] Vocabulary initialized.[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: d
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair d o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: d o
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 5 and 6
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair o g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o g
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: d
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair d o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: d o
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 14 and 15
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair o g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o g
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 72, Capacity: 300
[src/hash_table.c:274] Load factor: 0.240000
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 73, Capacity: 300
[src/hash_table.c:274] Load factor: 0.243333
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 74, Capacity: 300
[src/hash_table.c:274] Load factor: 0.246667
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 75, Capacity: 300
[src/hash_table.c:274] Load factor: 0.250000
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 76, Capacity: 300
[src/hash_table.c:274] Load factor: 0.253333
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 77, Capacity: 300
[src/hash_table.c:274] Load factor: 0.256667
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 78, Capacity: 300
[src/hash_table.c:274] Load factor: 0.260000
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 79, Capacity: 300
[src/hash_table.c:274] Load factor: 0.263333
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 80, Capacity: 300
[src/hash_table.c:274] Load factor: 0.266667
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 81, Capacity: 300
[src/hash_table.c:274] Load factor: 0.270000
[src/tokenizer.c:576] Processing tokens: 134 and 135
[src/tokenizer.c:578] Current token: d
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair d o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: d o
[src/hash_table.c:272] Current state - Size: 82, Capacity: 300
[src/hash_table.c:274] Load factor: 0.273333
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair o g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o g
[src/hash_table.c:272] Current state - Size: 83, Capacity: 300
[src/hash_table.c:274] Load factor: 0.276667
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 84, Capacity: 300
[src/hash_table.c:274] Load factor: 0.280000
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 85, Capacity: 300
[src/hash_table.c:274] Load factor: 0.283333
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 86, Capacity: 300
[src/hash_table.c:274] Load factor: 0.286667
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 87, Capacity: 300
[src/hash_table.c:274] Load factor: 0.290000
[src/tokenizer.c:576] Processing tokens: 144 and 145
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 88, Capacity: 300
[src/hash_table.c:274] Load factor: 0.293333
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 89, Capacity: 300
[src/hash_table.c:274] Load factor: 0.296667
[src/tokenizer.c:576] Processing tokens: 148 and 149
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 90, Capacity: 300
[src/hash_table.c:274] Load factor: 0.300000
[src/tokenizer.c:576] Processing tokens: 149 and 150
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 91, Capacity: 300
[src/hash_table.c:274] Load factor: 0.303333
[src/tokenizer.c:576] Processing tokens: 150 and 151
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 92, Capacity: 300
[src/hash_table.c:274] Load factor: 0.306667
[src/tokenizer.c:576] Processing tokens: 151 and 152
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 93, Capacity: 300
[src/hash_table.c:274] Load factor: 0.310000
[src/tokenizer.c:576] Processing tokens: 152 and 153
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 94, Capacity: 300
[src/hash_table.c:274] Load factor: 0.313333
[src/tokenizer.c:576] Processing tokens: 155 and 156
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 95, Capacity: 300
[src/hash_table.c:274] Load factor: 0.316667
[src/tokenizer.c:576] Processing tokens: 156 and 157
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 96, Capacity: 300
[src/hash_table.c:274] Load factor: 0.320000
[src/tokenizer.c:576] Processing tokens: 157 and 158
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 97, Capacity: 300
[src/hash_table.c:274] Load factor: 0.323333
[src/tokenizer.c:576] Processing tokens: 160 and 161
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 98, Capacity: 300
[src/hash_table.c:274] Load factor: 0.326667
[src/tokenizer.c:576] Processing tokens: 161 and 162
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 99, Capacity: 300
[src/hash_table.c:274] Load factor: 0.330000
[src/tokenizer.c:576] Processing tokens: 162 and 163
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 100, Capacity: 300
[src/hash_table.c:274] Load factor: 0.333333
[src/tokenizer.c:576] Processing tokens: 163 and 164
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 101, Capacity: 300
[src/hash_table.c:274] Load factor: 0.336667
[src/tokenizer.c:576] Processing tokens: 164 and 165
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 102, Capacity: 300
[src/hash_table.c:274] Load factor: 0.340000
[src/tokenizer.c:855] Most frequent pair: d o  freq: 1
[src/tokenizer.c:676] Token created: 0x204c39b0, text: d
[src/tokenizer.c:676] Token created: 0x204c3890, text: o
[src/tokenizer.c:676] Token created: 0x204c3850, text: do
[src/tokenizer.c:686] Token text freed: 0x204be5a0
[src/tokenizer.c:690] Token freed: 0x204be5a0 
[src/tokenizer.c:676] Token created: 0x204be5a0, text: do
[src/tokenizer.c:686] Token text freed: 0x204be5c0
[src/tokenizer.c:690] Token freed: 0x204be5c0 
[src/tokenizer.c:686] Token text freed: 0x204be480
[src/tokenizer.c:690] Token freed: 0x204be480 
[src/tokenizer.c:676] Token created: 0x204be480, text: do
[src/tokenizer.c:686] Token text freed: 0x204be4c0
[src/tokenizer.c:690] Token freed: 0x204be4c0 
[src/tokenizer.c:686] Token text freed: 0x204c0d90
[src/tokenizer.c:690] Token freed: 0x204c0d90 
[src/tokenizer.c:676] Token created: 0x204c0d90, text: do
[src/tokenizer.c:686] Token text freed: 0x204c0db0
[src/tokenizer.c:690] Token freed: 0x204c0db0 
[src/tokenizer.c:686] Token text freed: 0x204c39b0
[src/tokenizer.c:690] Token freed: 0x204c39b0 
[src/tokenizer.c:686] Token text freed: 0x204c3890
[src/tokenizer.c:690] Token freed: 0x204c3890 
[src/tokenizer.c:686] Token text freed: 0x204c3850
[src/tokenizer.c:690] Token freed: 0x204c3850 
[src/tokenizer.c:676] Token created: 0x204c3850, text: do
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 72, Capacity: 300
[src/hash_table.c:274] Load factor: 0.240000
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 73, Capacity: 300
[src/hash_table.c:274] Load factor: 0.243333
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 74, Capacity: 300
[src/hash_table.c:274] Load factor: 0.246667
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 75, Capacity: 300
[src/hash_table.c:274] Load factor: 0.250000
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 76, Capacity: 300
[src/hash_table.c:274] Load factor: 0.253333
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 77, Capacity: 300
[src/hash_table.c:274] Load factor: 0.256667
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 78, Capacity: 300
[src/hash_table.c:274] Load factor: 0.260000
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 79, Capacity: 300
[src/hash_table.c:274] Load factor: 0.263333
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 80, Capacity: 300
[src/hash_table.c:274] Load factor: 0.266667
[src/tokenizer.c:576] Processing tokens: 137 and 138
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 81, Capacity: 300
[src/hash_table.c:274] Load factor: 0.270000
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 82, Capacity: 300
[src/hash_table.c:274] Load factor: 0.273333
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 83, Capacity: 300
[src/hash_table.c:274] Load factor: 0.276667
[src/tokenizer.c:576] Processing tokens: 142 and 143
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 84, Capacity: 300
[src/hash_table.c:274] Load factor: 0.280000
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair o r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o r
[src/hash_table.c:272] Current state - Size: 85, Capacity: 300
[src/hash_table.c:274] Load factor: 0.283333
[src/tokenizer.c:576] Processing tokens: 146 and 147
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair r a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r a
[src/hash_table.c:272] Current state - Size: 86, Capacity: 300
[src/hash_table.c:274] Load factor: 0.286667
[src/tokenizer.c:576] Processing tokens: 147 and 148
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 87, Capacity: 300
[src/hash_table.c:274] Load factor: 0.290000
[src/tokenizer.c:576] Processing tokens: 148 and 149
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 88, Capacity: 300
[src/hash_table.c:274] Load factor: 0.293333
[src/tokenizer.c:576] Processing tokens: 149 and 150
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 89, Capacity: 300
[src/hash_table.c:274] Load factor: 0.296667
[src/tokenizer.c:576] Processing tokens: 152 and 153
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 90, Capacity: 300
[src/hash_table.c:274] Load factor: 0.300000
[src/tokenizer.c:576] Processing tokens: 153 and 154
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 91, Capacity: 300
[src/hash_table.c:274] Load factor: 0.303333
[src/tokenizer.c:576] Processing tokens: 154 and 155
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 92, Capacity: 300
[src/hash_table.c:274] Load factor: 0.306667
[src/tokenizer.c:576] Processing tokens: 157 and 158
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 93, Capacity: 300
[src/hash_table.c:274] Load factor: 0.310000
[src/tokenizer.c:576] Processing tokens: 158 and 159
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 94, Capacity: 300
[src/hash_table.c:274] Load factor: 0.313333
[src/tokenizer.c:576] Processing tokens: 159 and 160
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 95, Capacity: 300
[src/hash_table.c:274] Load factor: 0.316667
[src/tokenizer.c:576] Processing tokens: 160 and 161
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 96, Capacity: 300
[src/hash_table.c:274] Load factor: 0.320000
[src/tokenizer.c:576] Processing tokens: 161 and 162
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 97, Capacity: 300
[src/hash_table.c:274] Load factor: 0.323333
[src/tokenizer.c:855] Most frequent pair: r a  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4350, text: r
[src/tokenizer.c:676] Token created: 0x204c5180, text: a
[src/tokenizer.c:676] Token created: 0x204c5160, text: ra
[src/tokenizer.c:686] Token text freed: 0x204bedf0
[src/tokenizer.c:690] Token freed: 0x204bedf0 
[src/tokenizer.c:676] Token created: 0x204bedf0, text: ra
[src/tokenizer.c:686] Token text freed: 0x204bee30
[src/tokenizer.c:690] Token freed: 0x204bee30 
[src/tokenizer.c:686] Token text freed: 0x204bf2f0
[src/tokenizer.c:690] Token freed: 0x204bf2f0 
[src/tokenizer.c:676] Token created: 0x204bf2f0, text: ra
[src/tokenizer.c:686] Token text freed: 0x204bf330
[src/tokenizer.c:690] Token freed: 0x204bf330 
[src/tokenizer.c:686] Token text freed: 0x204c1150
[src/tokenizer.c:690] Token freed: 0x204c1150 
[src/tokenizer.c:676] Token created: 0x204c1150, text: ra
[src/tokenizer.c:686] Token text freed: 0x204c1190
[src/tokenizer.c:690] Token freed: 0x204c1190 
[src/tokenizer.c:686] Token text freed: 0x204c4350
[src/tokenizer.c:690] Token freed: 0x204c4350 
[src/tokenizer.c:686] Token text freed: 0x204c5180
[src/tokenizer.c:690] Token freed: 0x204c5180 
[src/tokenizer.c:686] Token text freed: 0x204c5160
[src/tokenizer.c:690] Token freed: 0x204c5160 
[src/tokenizer.c:676] Token created: 0x204c5160, text: ra
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 72, Capacity: 300
[src/hash_table.c:274] Load factor: 0.240000
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 73, Capacity: 300
[src/hash_table.c:274] Load factor: 0.243333
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 74, Capacity: 300
[src/hash_table.c:274] Load factor: 0.246667
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 133 and 134
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 75, Capacity: 300
[src/hash_table.c:274] Load factor: 0.250000
[src/tokenizer.c:576] Processing tokens: 134 and 135
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 76, Capacity: 300
[src/hash_table.c:274] Load factor: 0.253333
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 77, Capacity: 300
[src/hash_table.c:274] Load factor: 0.256667
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 78, Capacity: 300
[src/hash_table.c:274] Load factor: 0.260000
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 79, Capacity: 300
[src/hash_table.c:274] Load factor: 0.263333
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 80, Capacity: 300
[src/hash_table.c:274] Load factor: 0.266667
[src/tokenizer.c:576] Processing tokens: 143 and 144
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 144 and 145
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 81, Capacity: 300
[src/hash_table.c:274] Load factor: 0.270000
[src/tokenizer.c:576] Processing tokens: 146 and 147
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 82, Capacity: 300
[src/hash_table.c:274] Load factor: 0.273333
[src/tokenizer.c:576] Processing tokens: 149 and 150
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 83, Capacity: 300
[src/hash_table.c:274] Load factor: 0.276667
[src/tokenizer.c:576] Processing tokens: 150 and 151
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 84, Capacity: 300
[src/hash_table.c:274] Load factor: 0.280000
[src/tokenizer.c:576] Processing tokens: 151 and 152
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 85, Capacity: 300
[src/hash_table.c:274] Load factor: 0.283333
[src/tokenizer.c:576] Processing tokens: 154 and 155
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair b a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b a
[src/hash_table.c:272] Current state - Size: 86, Capacity: 300
[src/hash_table.c:274] Load factor: 0.286667
[src/tokenizer.c:576] Processing tokens: 155 and 156
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 87, Capacity: 300
[src/hash_table.c:274] Load factor: 0.290000
[src/tokenizer.c:576] Processing tokens: 156 and 157
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 88, Capacity: 300
[src/hash_table.c:274] Load factor: 0.293333
[src/tokenizer.c:576] Processing tokens: 157 and 158
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair a n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a n
[src/hash_table.c:272] Current state - Size: 89, Capacity: 300
[src/hash_table.c:274] Load factor: 0.296667
[src/tokenizer.c:576] Processing tokens: 158 and 159
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair n a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n a
[src/hash_table.c:272] Current state - Size: 90, Capacity: 300
[src/hash_table.c:274] Load factor: 0.300000
[src/tokenizer.c:855] Most frequent pair: a n  freq: 1
[src/tokenizer.c:676] Token created: 0x204c3f50, text: a
[src/tokenizer.c:676] Token created: 0x204c3a70, text: n
[src/tokenizer.c:676] Token created: 0x204c3b90, text: an
[src/tokenizer.c:686] Token text freed: 0x204befb0
[src/tokenizer.c:690] Token freed: 0x204befb0 
[src/tokenizer.c:676] Token created: 0x204befb0, text: an
[src/tokenizer.c:686] Token text freed: 0x204beff0
[src/tokenizer.c:690] Token freed: 0x204beff0 
[src/tokenizer.c:686] Token text freed: 0x204bf030
[src/tokenizer.c:690] Token freed: 0x204bf030 
[src/tokenizer.c:676] Token created: 0x204bf030, text: an
[src/tokenizer.c:686] Token text freed: 0x204bf070
[src/tokenizer.c:690] Token freed: 0x204bf070 
[src/tokenizer.c:686] Token text freed: 0x204bf520
[src/tokenizer.c:690] Token freed: 0x204bf520 
[src/tokenizer.c:676] Token created: 0x204bf520, text: an
[src/tokenizer.c:686] Token text freed: 0x204bf560
[src/tokenizer.c:690] Token freed: 0x204bf560 
[src/tokenizer.c:686] Token text freed: 0x204bf5a0
[src/tokenizer.c:690] Token freed: 0x204bf5a0 
[src/tokenizer.c:676] Token created: 0x204bf5a0, text: an
[src/tokenizer.c:686] Token text freed: 0x204bf5e0
[src/tokenizer.c:690] Token freed: 0x204bf5e0 
[src/tokenizer.c:686] Token text freed: 0x204c1470
[src/tokenizer.c:690] Token freed: 0x204c1470 
[src/tokenizer.c:676] Token created: 0x204c1470, text: an
[src/tokenizer.c:686] Token text freed: 0x204c14b0
[src/tokenizer.c:690] Token freed: 0x204c14b0 
[src/tokenizer.c:686] Token text freed: 0x204c14f0
[src/tokenizer.c:690] Token freed: 0x204c14f0 
[src/tokenizer.c:676] Token created: 0x204c14f0, text: an
[src/tokenizer.c:686] Token text freed: 0x204c1530
[src/tokenizer.c:690] Token freed: 0x204c1530 
[src/tokenizer.c:686] Token text freed: 0x204c3f50
[src/tokenizer.c:690] Token freed: 0x204c3f50 
[src/tokenizer.c:686] Token text freed: 0x204c3a70
[src/tokenizer.c:690] Token freed: 0x204c3a70 
[src/tokenizer.c:686] Token text freed: 0x204c3b90
[src/tokenizer.c:690] Token freed: 0x204c3b90 
[src/tokenizer.c:676] Token created: 0x204c3b90, text: an
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: f
[src/tokenizer.c:598] Inserting freq pair y f into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y f
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: f
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair f u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: f u
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair u l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u l
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 72, Capacity: 300
[src/hash_table.c:274] Load factor: 0.240000
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 73, Capacity: 300
[src/hash_table.c:274] Load factor: 0.243333
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 74, Capacity: 300
[src/hash_table.c:274] Load factor: 0.246667
[src/tokenizer.c:576] Processing tokens: 142 and 143
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 75, Capacity: 300
[src/hash_table.c:274] Load factor: 0.250000
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 76, Capacity: 300
[src/hash_table.c:274] Load factor: 0.253333
[src/tokenizer.c:576] Processing tokens: 146 and 147
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 77, Capacity: 300
[src/hash_table.c:274] Load factor: 0.256667
[src/tokenizer.c:576] Processing tokens: 147 and 148
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 78, Capacity: 300
[src/hash_table.c:274] Load factor: 0.260000
[src/tokenizer.c:576] Processing tokens: 150 and 151
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 151 and 152
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 152 and 153
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: f u  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5100, text: f
[src/tokenizer.c:676] Token created: 0x204c1d60, text: u
[src/tokenizer.c:676] Token created: 0x204c5960, text: fu
[src/tokenizer.c:686] Token text freed: 0x204c0810
[src/tokenizer.c:690] Token freed: 0x204c0810 
[src/tokenizer.c:676] Token created: 0x204c0810, text: fu
[src/tokenizer.c:686] Token text freed: 0x204c0850
[src/tokenizer.c:690] Token freed: 0x204c0850 
[src/tokenizer.c:686] Token text freed: 0x204c0c70
[src/tokenizer.c:690] Token freed: 0x204c0c70 
[src/tokenizer.c:676] Token created: 0x204c0c70, text: fu
[src/tokenizer.c:686] Token text freed: 0x204c0cb0
[src/tokenizer.c:690] Token freed: 0x204c0cb0 
[src/tokenizer.c:686] Token text freed: 0x204c5100
[src/tokenizer.c:690] Token freed: 0x204c5100 
[src/tokenizer.c:686] Token text freed: 0x204c1d60
[src/tokenizer.c:690] Token freed: 0x204c1d60 
[src/tokenizer.c:686] Token text freed: 0x204c5960
[src/tokenizer.c:690] Token freed: 0x204c5960 
[src/tokenizer.c:676] Token created: 0x204c5960, text: fu
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair p y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p y
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 133 and 134
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 134 and 135
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 137 and 138
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 143 and 144
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 72, Capacity: 300
[src/hash_table.c:274] Load factor: 0.240000
[src/tokenizer.c:576] Processing tokens: 144 and 145
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 73, Capacity: 300
[src/hash_table.c:274] Load factor: 0.243333
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 74, Capacity: 300
[src/hash_table.c:274] Load factor: 0.246667
[src/tokenizer.c:576] Processing tokens: 148 and 149
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 149 and 150
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 150 and 151
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: p y  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5940, text: p
[src/tokenizer.c:676] Token created: 0x204c5220, text: y
[src/tokenizer.c:676] Token created: 0x204c54e0, text: py
[src/tokenizer.c:686] Token text freed: 0x204c0570
[src/tokenizer.c:690] Token freed: 0x204c0570 
[src/tokenizer.c:676] Token created: 0x204c0570, text: py
[src/tokenizer.c:686] Token text freed: 0x204c05b0
[src/tokenizer.c:690] Token freed: 0x204c05b0 
[src/tokenizer.c:686] Token text freed: 0x204c09b0
[src/tokenizer.c:690] Token freed: 0x204c09b0 
[src/tokenizer.c:676] Token created: 0x204c09b0, text: py
[src/tokenizer.c:686] Token text freed: 0x204c09f0
[src/tokenizer.c:690] Token freed: 0x204c09f0 
[src/tokenizer.c:686] Token text freed: 0x204c5940
[src/tokenizer.c:690] Token freed: 0x204c5940 
[src/tokenizer.c:686] Token text freed: 0x204c5220
[src/tokenizer.c:690] Token freed: 0x204c5220 
[src/tokenizer.c:686] Token text freed: 0x204c54e0
[src/tokenizer.c:690] Token freed: 0x204c54e0 
[src/tokenizer.c:676] Token created: 0x204c54e0, text: py
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: u
[src/tokenizer.c:598] Inserting freq pair l u into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l u
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: u
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair u e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: u e
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 137 and 138
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 69, Capacity: 300
[src/hash_table.c:274] Load factor: 0.230000
[src/tokenizer.c:576] Processing tokens: 142 and 143
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 70, Capacity: 300
[src/hash_table.c:274] Load factor: 0.233333
[src/tokenizer.c:576] Processing tokens: 143 and 144
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 71, Capacity: 300
[src/hash_table.c:274] Load factor: 0.236667
[src/tokenizer.c:576] Processing tokens: 146 and 147
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 147 and 148
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 148 and 149
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: u e  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4270, text: u
[src/tokenizer.c:676] Token created: 0x204c51c0, text: e
[src/tokenizer.c:676] Token created: 0x204c5a60, text: ue
[src/tokenizer.c:686] Token text freed: 0x204bf700
[src/tokenizer.c:690] Token freed: 0x204bf700 
[src/tokenizer.c:676] Token created: 0x204bf700, text: ue
[src/tokenizer.c:686] Token text freed: 0x204bf740
[src/tokenizer.c:690] Token freed: 0x204bf740 
[src/tokenizer.c:686] Token text freed: 0x204bfac0
[src/tokenizer.c:690] Token freed: 0x204bfac0 
[src/tokenizer.c:676] Token created: 0x204bfac0, text: ue
[src/tokenizer.c:686] Token text freed: 0x204bfb00
[src/tokenizer.c:690] Token freed: 0x204bfb00 
[src/tokenizer.c:686] Token text freed: 0x204c4270
[src/tokenizer.c:690] Token freed: 0x204c4270 
[src/tokenizer.c:686] Token text freed: 0x204c51c0
[src/tokenizer.c:690] Token freed: 0x204c51c0 
[src/tokenizer.c:686] Token text freed: 0x204c5a60
[src/tokenizer.c:690] Token freed: 0x204c5a60 
[src/tokenizer.c:676] Token created: 0x204c5a60, text: ue
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair p l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p l
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair l e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l e
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 133 and 134
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 134 and 135
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 64, Capacity: 300
[src/hash_table.c:274] Load factor: 0.213333
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 65, Capacity: 300
[src/hash_table.c:274] Load factor: 0.216667
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 66, Capacity: 300
[src/hash_table.c:274] Load factor: 0.220000
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 67, Capacity: 300
[src/hash_table.c:274] Load factor: 0.223333
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 68, Capacity: 300
[src/hash_table.c:274] Load factor: 0.226667
[src/tokenizer.c:576] Processing tokens: 144 and 145
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 145 and 146
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 146 and 147
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: l e  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4130, text: l
[src/tokenizer.c:676] Token created: 0x204c5660, text: e
[src/tokenizer.c:676] Token created: 0x204c5300, text: le
[src/tokenizer.c:686] Token text freed: 0x204becd0
[src/tokenizer.c:690] Token freed: 0x204becd0 
[src/tokenizer.c:676] Token created: 0x204becd0, text: le
[src/tokenizer.c:686] Token text freed: 0x204bed10
[src/tokenizer.c:690] Token freed: 0x204bed10 
[src/tokenizer.c:686] Token text freed: 0x204bf1d0
[src/tokenizer.c:690] Token freed: 0x204bf1d0 
[src/tokenizer.c:676] Token created: 0x204bf1d0, text: le
[src/tokenizer.c:686] Token text freed: 0x204bf210
[src/tokenizer.c:690] Token freed: 0x204bf210 
[src/tokenizer.c:686] Token text freed: 0x204c0f30
[src/tokenizer.c:690] Token freed: 0x204c0f30 
[src/tokenizer.c:676] Token created: 0x204c0f30, text: le
[src/tokenizer.c:686] Token text freed: 0x204c0f70
[src/tokenizer.c:690] Token freed: 0x204c0f70 
[src/tokenizer.c:686] Token text freed: 0x204c4130
[src/tokenizer.c:690] Token freed: 0x204c4130 
[src/tokenizer.c:686] Token text freed: 0x204c5660
[src/tokenizer.c:690] Token freed: 0x204c5660 
[src/tokenizer.c:686] Token text freed: 0x204c5300
[src/tokenizer.c:690] Token freed: 0x204c5300 
[src/tokenizer.c:676] Token created: 0x204c5300, text: le
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 59, Capacity: 300
[src/hash_table.c:274] Load factor: 0.196667
[src/tokenizer.c:576] Processing tokens: 133 and 134
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 60, Capacity: 300
[src/hash_table.c:274] Load factor: 0.200000
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: i
[src/tokenizer.c:598] Inserting freq pair b i into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b i
[src/hash_table.c:272] Current state - Size: 61, Capacity: 300
[src/hash_table.c:274] Load factor: 0.203333
[src/tokenizer.c:576] Processing tokens: 137 and 138
[src/tokenizer.c:578] Current token: i
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair i r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: i r
[src/hash_table.c:272] Current state - Size: 62, Capacity: 300
[src/hash_table.c:274] Load factor: 0.206667
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 63, Capacity: 300
[src/hash_table.c:274] Load factor: 0.210000
[src/tokenizer.c:576] Processing tokens: 141 and 142
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 142 and 143
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 143 and 144
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: b i  freq: 1
[src/tokenizer.c:676] Token created: 0x204c3b30, text: b
[src/tokenizer.c:676] Token created: 0x204c42d0, text: i
[src/tokenizer.c:676] Token created: 0x204c5200, text: bi
[src/tokenizer.c:686] Token text freed: 0x204bae10
[src/tokenizer.c:690] Token freed: 0x204bae10 
[src/tokenizer.c:676] Token created: 0x204bae10, text: bi
[src/tokenizer.c:686] Token text freed: 0x204bae50
[src/tokenizer.c:690] Token freed: 0x204bae50 
[src/tokenizer.c:686] Token text freed: 0x204bce00
[src/tokenizer.c:690] Token freed: 0x204bce00 
[src/tokenizer.c:676] Token created: 0x204bce00, text: bi
[src/tokenizer.c:686] Token text freed: 0x204bea90
[src/tokenizer.c:690] Token freed: 0x204bea90 
[src/tokenizer.c:686] Token text freed: 0x204c12b0
[src/tokenizer.c:690] Token freed: 0x204c12b0 
[src/tokenizer.c:676] Token created: 0x204c12b0, text: bi
[src/tokenizer.c:686] Token text freed: 0x204c12d0
[src/tokenizer.c:690] Token freed: 0x204c12d0 
[src/tokenizer.c:686] Token text freed: 0x204c3b30
[src/tokenizer.c:690] Token freed: 0x204c3b30 
[src/tokenizer.c:686] Token text freed: 0x204c42d0
[src/tokenizer.c:690] Token freed: 0x204c42d0 
[src/tokenizer.c:686] Token text freed: 0x204c5200
[src/tokenizer.c:690] Token freed: 0x204c5200 
[src/tokenizer.c:676] Token created: 0x204c5200, text: bi
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 1 and 2
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 4 and 5
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 11 and 12
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 14 and 15
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair c a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c a
[src/hash_table.c:272] Current state - Size: 54, Capacity: 300
[src/hash_table.c:274] Load factor: 0.180000
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: t
[src/tokenizer.c:598] Inserting freq pair a t into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a t
[src/hash_table.c:272] Current state - Size: 55, Capacity: 300
[src/hash_table.c:274] Load factor: 0.183333
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 56, Capacity: 300
[src/hash_table.c:274] Load factor: 0.186667
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 57, Capacity: 300
[src/hash_table.c:274] Load factor: 0.190000
[src/tokenizer.c:576] Processing tokens: 134 and 135
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 58, Capacity: 300
[src/hash_table.c:274] Load factor: 0.193333
[src/tokenizer.c:576] Processing tokens: 138 and 139
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 139 and 140
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 140 and 141
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: a t  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5620, text: a
[src/tokenizer.c:676] Token created: 0x204c4370, text: t
[src/tokenizer.c:676] Token created: 0x204c4c60, text: at
[src/tokenizer.c:686] Token text freed: 0x204baf40
[src/tokenizer.c:690] Token freed: 0x204baf40 
[src/tokenizer.c:676] Token created: 0x204baf40, text: at
[src/tokenizer.c:686] Token text freed: 0x204baf60
[src/tokenizer.c:690] Token freed: 0x204baf60 
[src/tokenizer.c:686] Token text freed: 0x204bccc0
[src/tokenizer.c:690] Token freed: 0x204bccc0 
[src/tokenizer.c:676] Token created: 0x204bccc0, text: at
[src/tokenizer.c:686] Token text freed: 0x204bcd00
[src/tokenizer.c:690] Token freed: 0x204bcd00 
[src/tokenizer.c:686] Token text freed: 0x204c0ff0
[src/tokenizer.c:690] Token freed: 0x204c0ff0 
[src/tokenizer.c:676] Token created: 0x204c0ff0, text: at
[src/tokenizer.c:686] Token text freed: 0x204c1030
[src/tokenizer.c:690] Token freed: 0x204c1030 
[src/tokenizer.c:686] Token text freed: 0x204c5620
[src/tokenizer.c:690] Token freed: 0x204c5620 
[src/tokenizer.c:686] Token text freed: 0x204c4370
[src/tokenizer.c:690] Token freed: 0x204c4370 
[src/tokenizer.c:686] Token text freed: 0x204c4c60
[src/tokenizer.c:690] Token freed: 0x204c4c60 
[src/tokenizer.c:676] Token created: 0x204c4c60, text: at
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair e d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e d
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair g r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g r
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair r e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r e
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair e e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e e
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 47, Capacity: 300
[src/hash_table.c:274] Load factor: 0.156667
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 48, Capacity: 300
[src/hash_table.c:274] Load factor: 0.160000
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 49, Capacity: 300
[src/hash_table.c:274] Load factor: 0.163333
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 50, Capacity: 300
[src/hash_table.c:274] Load factor: 0.166667
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 51, Capacity: 300
[src/hash_table.c:274] Load factor: 0.170000
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 52, Capacity: 300
[src/hash_table.c:274] Load factor: 0.173333
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 53, Capacity: 300
[src/hash_table.c:274] Load factor: 0.176667
[src/tokenizer.c:576] Processing tokens: 135 and 136
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 136 and 137
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 137 and 138
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: r e  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4090, text: r
[src/tokenizer.c:676] Token created: 0x204c54c0, text: e
[src/tokenizer.c:676] Token created: 0x204c43d0, text: re
[src/tokenizer.c:686] Token text freed: 0x204bf7a0
[src/tokenizer.c:690] Token freed: 0x204bf7a0 
[src/tokenizer.c:676] Token created: 0x204bf7a0, text: re
[src/tokenizer.c:686] Token text freed: 0x204bf7e0
[src/tokenizer.c:690] Token freed: 0x204bf7e0 
[src/tokenizer.c:686] Token text freed: 0x204bf920
[src/tokenizer.c:690] Token freed: 0x204bf920 
[src/tokenizer.c:676] Token created: 0x204bf920, text: re
[src/tokenizer.c:686] Token text freed: 0x204bf960
[src/tokenizer.c:690] Token freed: 0x204bf960 
[src/tokenizer.c:686] Token text freed: 0x204bfb60
[src/tokenizer.c:690] Token freed: 0x204bfb60 
[src/tokenizer.c:676] Token created: 0x204bfb60, text: re
[src/tokenizer.c:686] Token text freed: 0x204bfba0
[src/tokenizer.c:690] Token freed: 0x204bfba0 
[src/tokenizer.c:686] Token text freed: 0x204bfd00
[src/tokenizer.c:690] Token freed: 0x204bfd00 
[src/tokenizer.c:676] Token created: 0x204bfd00, text: re
[src/tokenizer.c:686] Token text freed: 0x204bfd40
[src/tokenizer.c:690] Token freed: 0x204bfd40 
[src/tokenizer.c:686] Token text freed: 0x204c4090
[src/tokenizer.c:690] Token freed: 0x204c4090 
[src/tokenizer.c:686] Token text freed: 0x204c54c0
[src/tokenizer.c:690] Token freed: 0x204c54c0 
[src/tokenizer.c:686] Token text freed: 0x204c43d0
[src/tokenizer.c:690] Token freed: 0x204c43d0 
[src/tokenizer.c:676] Token created: 0x204c43d0, text: re
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair b an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b an
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:598] Inserting freq pair an an into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an an
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair an a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: an a
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 124 and 125
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 128 and 129
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 46, Capacity: 300
[src/hash_table.c:274] Load factor: 0.153333
[src/tokenizer.c:576] Processing tokens: 131 and 132
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair b an.
[src/tokenizer.c:576] Processing tokens: 132 and 133
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: an
[src/tokenizer.c:593] Incrementing frequency of freq pair an an.
[src/tokenizer.c:576] Processing tokens: 133 and 134
[src/tokenizer.c:578] Current token: an
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair an a.
[src/tokenizer.c:855] Most frequent pair: an an freq: 3
[src/tokenizer.c:676] Token created: 0x204c55a0, text: an
[src/tokenizer.c:676] Token created: 0x204c4b80, text: an
[src/tokenizer.c:676] Token created: 0x204c53e0, text: anan
[src/tokenizer.c:686] Token text freed: 0x204befb0
[src/tokenizer.c:690] Token freed: 0x204befb0 
[src/tokenizer.c:676] Token created: 0x204befb0, text: anan
[src/tokenizer.c:686] Token text freed: 0x204bf030
[src/tokenizer.c:690] Token freed: 0x204bf030 
[src/tokenizer.c:686] Token text freed: 0x204bf520
[src/tokenizer.c:690] Token freed: 0x204bf520 
[src/tokenizer.c:676] Token created: 0x204bf520, text: anan
[src/tokenizer.c:686] Token text freed: 0x204bf5a0
[src/tokenizer.c:690] Token freed: 0x204bf5a0 
[src/tokenizer.c:686] Token text freed: 0x204c1470
[src/tokenizer.c:690] Token freed: 0x204c1470 
[src/tokenizer.c:676] Token created: 0x204c1470, text: anan
[src/tokenizer.c:686] Token text freed: 0x204c14f0
[src/tokenizer.c:690] Token freed: 0x204c14f0 
[src/tokenizer.c:686] Token text freed: 0x204c55a0
[src/tokenizer.c:690] Token freed: 0x204c55a0 
[src/tokenizer.c:686] Token text freed: 0x204c4b80
[src/tokenizer.c:690] Token freed: 0x204c4b80 
[src/tokenizer.c:686] Token text freed: 0x204c53e0
[src/tokenizer.c:690] Token freed: 0x204c53e0 
[src/tokenizer.c:676] Token created: 0x204c53e0, text: anan
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:598] Inserting freq pair b anan into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b anan
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair anan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: anan a
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 41, Capacity: 300
[src/hash_table.c:274] Load factor: 0.136667
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 42, Capacity: 300
[src/hash_table.c:274] Load factor: 0.140000
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair n g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n g
[src/hash_table.c:272] Current state - Size: 43, Capacity: 300
[src/hash_table.c:274] Load factor: 0.143333
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair g e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g e
[src/hash_table.c:272] Current state - Size: 44, Capacity: 300
[src/hash_table.c:274] Load factor: 0.146667
[src/tokenizer.c:576] Processing tokens: 125 and 126
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 45, Capacity: 300
[src/hash_table.c:274] Load factor: 0.150000
[src/tokenizer.c:576] Processing tokens: 129 and 130
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 130 and 131
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:855] Most frequent pair: g e  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5e70, text: g
[src/tokenizer.c:676] Token created: 0x204c42f0, text: e
[src/tokenizer.c:676] Token created: 0x204c3fb0, text: ge
[src/tokenizer.c:686] Token text freed: 0x204beeb0
[src/tokenizer.c:690] Token freed: 0x204beeb0 
[src/tokenizer.c:676] Token created: 0x204beeb0, text: ge
[src/tokenizer.c:686] Token text freed: 0x204beef0
[src/tokenizer.c:690] Token freed: 0x204beef0 
[src/tokenizer.c:686] Token text freed: 0x204bf3b0
[src/tokenizer.c:690] Token freed: 0x204bf3b0 
[src/tokenizer.c:676] Token created: 0x204bf3b0, text: ge
[src/tokenizer.c:686] Token text freed: 0x204bf3f0
[src/tokenizer.c:690] Token freed: 0x204bf3f0 
[src/tokenizer.c:686] Token text freed: 0x204c1210
[src/tokenizer.c:690] Token freed: 0x204c1210 
[src/tokenizer.c:676] Token created: 0x204c1210, text: ge
[src/tokenizer.c:686] Token text freed: 0x204c1250
[src/tokenizer.c:690] Token freed: 0x204c1250 
[src/tokenizer.c:686] Token text freed: 0x204c5e70
[src/tokenizer.c:690] Token freed: 0x204c5e70 
[src/tokenizer.c:686] Token text freed: 0x204c42f0
[src/tokenizer.c:690] Token freed: 0x204c42f0 
[src/tokenizer.c:686] Token text freed: 0x204c3fb0
[src/tokenizer.c:690] Token freed: 0x204c3fb0 
[src/tokenizer.c:676] Token created: 0x204c3fb0, text: ge
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:598] Inserting freq pair b anan into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b anan
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair anan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: anan a
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair p py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p py
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair h a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h a
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 33, Capacity: 300
[src/hash_table.c:274] Load factor: 0.110000
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair p py.
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 34, Capacity: 300
[src/hash_table.c:274] Load factor: 0.113333
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 35, Capacity: 300
[src/hash_table.c:274] Load factor: 0.116667
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 36, Capacity: 300
[src/hash_table.c:274] Load factor: 0.120000
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 37, Capacity: 300
[src/hash_table.c:274] Load factor: 0.123333
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair a p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a p
[src/hash_table.c:272] Current state - Size: 38, Capacity: 300
[src/hash_table.c:274] Load factor: 0.126667
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair p p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p p
[src/hash_table.c:272] Current state - Size: 39, Capacity: 300
[src/hash_table.c:274] Load factor: 0.130000
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 123 and 124
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 40, Capacity: 300
[src/hash_table.c:274] Load factor: 0.133333
[src/tokenizer.c:576] Processing tokens: 126 and 127
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 127 and 128
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:855] Most frequent pair: a p  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4330, text: a
[src/tokenizer.c:676] Token created: 0x204c11b0, text: p
[src/tokenizer.c:676] Token created: 0x204c5580, text: ap
[src/tokenizer.c:686] Token text freed: 0x204bec10
[src/tokenizer.c:690] Token freed: 0x204bec10 
[src/tokenizer.c:676] Token created: 0x204bec10, text: ap
[src/tokenizer.c:686] Token text freed: 0x204bec50
[src/tokenizer.c:690] Token freed: 0x204bec50 
[src/tokenizer.c:686] Token text freed: 0x204bf110
[src/tokenizer.c:690] Token freed: 0x204bf110 
[src/tokenizer.c:676] Token created: 0x204bf110, text: ap
[src/tokenizer.c:686] Token text freed: 0x204bf150
[src/tokenizer.c:690] Token freed: 0x204bf150 
[src/tokenizer.c:686] Token text freed: 0x204bfea0
[src/tokenizer.c:690] Token freed: 0x204bfea0 
[src/tokenizer.c:676] Token created: 0x204bfea0, text: ap
[src/tokenizer.c:686] Token text freed: 0x204c0530
[src/tokenizer.c:690] Token freed: 0x204c0530 
[src/tokenizer.c:686] Token text freed: 0x204c0930
[src/tokenizer.c:690] Token freed: 0x204c0930 
[src/tokenizer.c:676] Token created: 0x204c0930, text: ap
[src/tokenizer.c:686] Token text freed: 0x204c0970
[src/tokenizer.c:690] Token freed: 0x204c0970 
[src/tokenizer.c:686] Token text freed: 0x204c0e70
[src/tokenizer.c:690] Token freed: 0x204c0e70 
[src/tokenizer.c:676] Token created: 0x204c0e70, text: ap
[src/tokenizer.c:686] Token text freed: 0x204c0eb0
[src/tokenizer.c:690] Token freed: 0x204c0eb0 
[src/tokenizer.c:686] Token text freed: 0x204c4330
[src/tokenizer.c:690] Token freed: 0x204c4330 
[src/tokenizer.c:686] Token text freed: 0x204c11b0
[src/tokenizer.c:690] Token freed: 0x204c11b0 
[src/tokenizer.c:686] Token text freed: 0x204c5580
[src/tokenizer.c:690] Token freed: 0x204c5580 
[src/tokenizer.c:676] Token created: 0x204c5580, text: ap
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:598] Inserting freq pair b anan into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b anan
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair anan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: anan a
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair l ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: l ue
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair b l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b l
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: l
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair l ue.
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 31, Capacity: 300
[src/hash_table.c:274] Load factor: 0.103333
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 118 and 119
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 32, Capacity: 300
[src/hash_table.c:274] Load factor: 0.106667
[src/tokenizer.c:576] Processing tokens: 121 and 122
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 122 and 123
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:855] Most frequent pair: b l  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5920, text: b
[src/tokenizer.c:676] Token created: 0x204c4cc0, text: l
[src/tokenizer.c:676] Token created: 0x204c5680, text: bl
[src/tokenizer.c:686] Token text freed: 0x204bf6c0
[src/tokenizer.c:690] Token freed: 0x204bf6c0 
[src/tokenizer.c:676] Token created: 0x204bf6c0, text: bl
[src/tokenizer.c:686] Token text freed: 0x204bf6e0
[src/tokenizer.c:690] Token freed: 0x204bf6e0 
[src/tokenizer.c:686] Token text freed: 0x204bfa40
[src/tokenizer.c:690] Token freed: 0x204bfa40 
[src/tokenizer.c:676] Token created: 0x204bfa40, text: bl
[src/tokenizer.c:686] Token text freed: 0x204bfa80
[src/tokenizer.c:690] Token freed: 0x204bfa80 
[src/tokenizer.c:686] Token text freed: 0x204c5920
[src/tokenizer.c:690] Token freed: 0x204c5920 
[src/tokenizer.c:686] Token text freed: 0x204c4cc0
[src/tokenizer.c:690] Token freed: 0x204c4cc0 
[src/tokenizer.c:686] Token text freed: 0x204c5680
[src/tokenizer.c:690] Token freed: 0x204c5680 
[src/tokenizer.c:676] Token created: 0x204c5680, text: bl
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:598] Inserting freq pair b anan into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: b anan
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair anan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: anan a
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: bl
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair bl ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bl ue
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: bl
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair bl ue.
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 116 and 117
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 30, Capacity: 300
[src/hash_table.c:274] Load factor: 0.100000
[src/tokenizer.c:576] Processing tokens: 119 and 120
[src/tokenizer.c:578] Current token: b
[src/tokenizer.c:581] Next token: anan
[src/tokenizer.c:593] Incrementing frequency of freq pair b anan.
[src/tokenizer.c:576] Processing tokens: 120 and 121
[src/tokenizer.c:578] Current token: anan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair anan a.
[src/tokenizer.c:855] Most frequent pair: b anan freq: 3
[src/tokenizer.c:676] Token created: 0x204c3a30, text: b
[src/tokenizer.c:676] Token created: 0x204c1550, text: anan
[src/tokenizer.c:676] Token created: 0x204c3bf0, text: banan
[src/tokenizer.c:686] Token text freed: 0x204bef70
[src/tokenizer.c:690] Token freed: 0x204bef70 
[src/tokenizer.c:676] Token created: 0x204bef70, text: banan
[src/tokenizer.c:686] Token text freed: 0x204befb0
[src/tokenizer.c:690] Token freed: 0x204befb0 
[src/tokenizer.c:686] Token text freed: 0x204bf4e0
[src/tokenizer.c:690] Token freed: 0x204bf4e0 
[src/tokenizer.c:676] Token created: 0x204bf4e0, text: banan
[src/tokenizer.c:686] Token text freed: 0x204bf520
[src/tokenizer.c:690] Token freed: 0x204bf520 
[src/tokenizer.c:686] Token text freed: 0x204c1430
[src/tokenizer.c:690] Token freed: 0x204c1430 
[src/tokenizer.c:676] Token created: 0x204c1430, text: banan
[src/tokenizer.c:686] Token text freed: 0x204c1470
[src/tokenizer.c:690] Token freed: 0x204c1470 
[src/tokenizer.c:686] Token text freed: 0x204c3a30
[src/tokenizer.c:690] Token freed: 0x204c3a30 
[src/tokenizer.c:686] Token text freed: 0x204c1550
[src/tokenizer.c:690] Token freed: 0x204c1550 
[src/tokenizer.c:686] Token text freed: 0x204c3bf0
[src/tokenizer.c:690] Token freed: 0x204c3bf0 
[src/tokenizer.c:676] Token created: 0x204c3bf0, text: banan
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: bl
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:598] Inserting freq pair bl ue into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bl ue
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: bl
[src/tokenizer.c:581] Next token: ue
[src/tokenizer.c:593] Incrementing frequency of freq pair bl ue.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 114 and 115
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 29, Capacity: 300
[src/hash_table.c:274] Load factor: 0.096667
[src/tokenizer.c:576] Processing tokens: 117 and 118
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: bl ue freq: 2
[src/tokenizer.c:676] Token created: 0x204c3910, text: bl
[src/tokenizer.c:676] Token created: 0x204c4cc0, text: ue
[src/tokenizer.c:676] Token created: 0x204c58e0, text: blue
[src/tokenizer.c:686] Token text freed: 0x204bf6c0
[src/tokenizer.c:690] Token freed: 0x204bf6c0 
[src/tokenizer.c:676] Token created: 0x204bf6c0, text: blue
[src/tokenizer.c:686] Token text freed: 0x204bf700
[src/tokenizer.c:690] Token freed: 0x204bf700 
[src/tokenizer.c:686] Token text freed: 0x204bfa40
[src/tokenizer.c:690] Token freed: 0x204bfa40 
[src/tokenizer.c:676] Token created: 0x204bfa40, text: blue
[src/tokenizer.c:686] Token text freed: 0x204bfac0
[src/tokenizer.c:690] Token freed: 0x204bfac0 
[src/tokenizer.c:686] Token text freed: 0x204c3910
[src/tokenizer.c:690] Token freed: 0x204c3910 
[src/tokenizer.c:686] Token text freed: 0x204c4cc0
[src/tokenizer.c:690] Token freed: 0x204c4cc0 
[src/tokenizer.c:686] Token text freed: 0x204c58e0
[src/tokenizer.c:690] Token freed: 0x204c58e0 
[src/tokenizer.c:676] Token created: 0x204c58e0, text: blue
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair s a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s a
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: a
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair a d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: a d
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 26, Capacity: 300
[src/hash_table.c:274] Load factor: 0.086667
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 27, Capacity: 300
[src/hash_table.c:274] Load factor: 0.090000
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 111 and 112
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 112 and 113
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 28, Capacity: 300
[src/hash_table.c:274] Load factor: 0.093333
[src/tokenizer.c:576] Processing tokens: 115 and 116
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: a d  freq: 1
[src/tokenizer.c:676] Token created: 0x204c5840, text: a
[src/tokenizer.c:676] Token created: 0x204c3a30, text: d
[src/tokenizer.c:676] Token created: 0x204c1550, text: ad
[src/tokenizer.c:686] Token text freed: 0x204c0630
[src/tokenizer.c:690] Token freed: 0x204c0630 
[src/tokenizer.c:676] Token created: 0x204c0630, text: ad
[src/tokenizer.c:686] Token text freed: 0x204c0670
[src/tokenizer.c:690] Token freed: 0x204c0670 
[src/tokenizer.c:686] Token text freed: 0x204c0a70
[src/tokenizer.c:690] Token freed: 0x204c0a70 
[src/tokenizer.c:676] Token created: 0x204c0a70, text: ad
[src/tokenizer.c:686] Token text freed: 0x204c0ab0
[src/tokenizer.c:690] Token freed: 0x204c0ab0 
[src/tokenizer.c:686] Token text freed: 0x204c5840
[src/tokenizer.c:690] Token freed: 0x204c5840 
[src/tokenizer.c:686] Token text freed: 0x204c3a30
[src/tokenizer.c:690] Token freed: 0x204c3a30 
[src/tokenizer.c:686] Token text freed: 0x204c1550
[src/tokenizer.c:690] Token freed: 0x204c1550 
[src/tokenizer.c:676] Token created: 0x204c1550, text: ad
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:598] Inserting freq pair bi r into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bi r
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 7 and 8
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 10 and 11
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 13 and 14
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 16 and 17
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 23, Capacity: 300
[src/hash_table.c:274] Load factor: 0.076667
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 24, Capacity: 300
[src/hash_table.c:274] Load factor: 0.080000
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 109 and 110
[src/tokenizer.c:578] Current token: bi
[src/tokenizer.c:581] Next token: r
[src/tokenizer.c:593] Incrementing frequency of freq pair bi r.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: r
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair r d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: r d
[src/hash_table.c:272] Current state - Size: 25, Capacity: 300
[src/hash_table.c:274] Load factor: 0.083333
[src/tokenizer.c:576] Processing tokens: 113 and 114
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: bi r freq: 3
[src/tokenizer.c:676] Token created: 0x204c35b0, text: bi
[src/tokenizer.c:676] Token created: 0x204c5ae0, text: r
[src/tokenizer.c:676] Token created: 0x204c5480, text: bir
[src/tokenizer.c:686] Token text freed: 0x204bae10
[src/tokenizer.c:690] Token freed: 0x204bae10 
[src/tokenizer.c:676] Token created: 0x204bae10, text: bir
[src/tokenizer.c:686] Token text freed: 0x204be380
[src/tokenizer.c:690] Token freed: 0x204be380 
[src/tokenizer.c:686] Token text freed: 0x204bce00
[src/tokenizer.c:690] Token freed: 0x204bce00 
[src/tokenizer.c:676] Token created: 0x204bce00, text: bir
[src/tokenizer.c:686] Token text freed: 0x204bead0
[src/tokenizer.c:690] Token freed: 0x204bead0 
[src/tokenizer.c:686] Token text freed: 0x204c12b0
[src/tokenizer.c:690] Token freed: 0x204c12b0 
[src/tokenizer.c:676] Token created: 0x204c12b0, text: bir
[src/tokenizer.c:686] Token text freed: 0x204c1310
[src/tokenizer.c:690] Token freed: 0x204c1310 
[src/tokenizer.c:686] Token text freed: 0x204c35b0
[src/tokenizer.c:690] Token freed: 0x204c35b0 
[src/tokenizer.c:686] Token text freed: 0x204c5ae0
[src/tokenizer.c:690] Token freed: 0x204c5ae0 
[src/tokenizer.c:686] Token text freed: 0x204c5480
[src/tokenizer.c:690] Token freed: 0x204c5480 
[src/tokenizer.c:676] Token created: 0x204c5480, text: bir
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:598] Inserting freq pair h ap into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h ap
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:598] Inserting freq pair ap py into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap py
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: ap
[src/tokenizer.c:593] Incrementing frequency of freq pair h ap.
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: py
[src/tokenizer.c:593] Incrementing frequency of freq pair ap py.
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 22, Capacity: 300
[src/hash_table.c:274] Load factor: 0.073333
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 104 and 105
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 107 and 108
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 110 and 111
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: ap py freq: 2
[src/tokenizer.c:676] Token created: 0x204c57a0, text: ap
[src/tokenizer.c:676] Token created: 0x204c5600, text: py
[src/tokenizer.c:676] Token created: 0x204c4e80, text: appy
[src/tokenizer.c:686] Token text freed: 0x204bfea0
[src/tokenizer.c:690] Token freed: 0x204bfea0 
[src/tokenizer.c:676] Token created: 0x204bfea0, text: appy
[src/tokenizer.c:686] Token text freed: 0x204c0570
[src/tokenizer.c:690] Token freed: 0x204c0570 
[src/tokenizer.c:686] Token text freed: 0x204c0930
[src/tokenizer.c:690] Token freed: 0x204c0930 
[src/tokenizer.c:676] Token created: 0x204c0930, text: appy
[src/tokenizer.c:686] Token text freed: 0x204c09b0
[src/tokenizer.c:690] Token freed: 0x204c09b0 
[src/tokenizer.c:686] Token text freed: 0x204c57a0
[src/tokenizer.c:690] Token freed: 0x204c57a0 
[src/tokenizer.c:686] Token text freed: 0x204c5600
[src/tokenizer.c:690] Token freed: 0x204c5600 
[src/tokenizer.c:686] Token text freed: 0x204c4e80
[src/tokenizer.c:690] Token freed: 0x204c4e80 
[src/tokenizer.c:676] Token created: 0x204c4e80, text: appy
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:598] Inserting freq pair y fu into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y fu
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:598] Inserting freq pair fu l into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: fu l
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 21, Capacity: 300
[src/hash_table.c:274] Load factor: 0.070000
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: fu
[src/tokenizer.c:593] Incrementing frequency of freq pair y fu.
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: fu
[src/tokenizer.c:581] Next token: l
[src/tokenizer.c:593] Incrementing frequency of freq pair fu l.
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 102 and 103
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 105 and 106
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 108 and 109
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: fu l freq: 2
[src/tokenizer.c:676] Token created: 0x204c1270, text: fu
[src/tokenizer.c:676] Token created: 0x204c5640, text: l
[src/tokenizer.c:676] Token created: 0x204c40d0, text: ful
[src/tokenizer.c:686] Token text freed: 0x204c0810
[src/tokenizer.c:690] Token freed: 0x204c0810 
[src/tokenizer.c:676] Token created: 0x204c0810, text: ful
[src/tokenizer.c:686] Token text freed: 0x204c0890
[src/tokenizer.c:690] Token freed: 0x204c0890 
[src/tokenizer.c:686] Token text freed: 0x204c0c70
[src/tokenizer.c:690] Token freed: 0x204c0c70 
[src/tokenizer.c:676] Token created: 0x204c0c70, text: ful
[src/tokenizer.c:686] Token text freed: 0x204c0cf0
[src/tokenizer.c:690] Token freed: 0x204c0cf0 
[src/tokenizer.c:686] Token text freed: 0x204c1270
[src/tokenizer.c:690] Token freed: 0x204c1270 
[src/tokenizer.c:686] Token text freed: 0x204c5640
[src/tokenizer.c:690] Token freed: 0x204c5640 
[src/tokenizer.c:686] Token text freed: 0x204c40d0
[src/tokenizer.c:690] Token freed: 0x204c40d0 
[src/tokenizer.c:676] Token created: 0x204c40d0, text: ful
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:598] Inserting freq pair banan a into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: banan a
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 20, Capacity: 300
[src/hash_table.c:274] Load factor: 0.066667
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 99 and 100
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 100 and 101
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 103 and 104
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 106 and 107
[src/tokenizer.c:578] Current token: banan
[src/tokenizer.c:581] Next token: a
[src/tokenizer.c:593] Incrementing frequency of freq pair banan a.
[src/tokenizer.c:855] Most frequent pair: banan a freq: 3
[src/tokenizer.c:676] Token created: 0x204c3b50, text: banan
[src/tokenizer.c:676] Token created: 0x204c57a0, text: a
[src/tokenizer.c:676] Token created: 0x204c5600, text: banana
[src/tokenizer.c:686] Token text freed: 0x204bef70
[src/tokenizer.c:690] Token freed: 0x204bef70 
[src/tokenizer.c:676] Token created: 0x204bef70, text: banana
[src/tokenizer.c:686] Token text freed: 0x204bf0b0
[src/tokenizer.c:690] Token freed: 0x204bf0b0 
[src/tokenizer.c:686] Token text freed: 0x204bf4e0
[src/tokenizer.c:690] Token freed: 0x204bf4e0 
[src/tokenizer.c:676] Token created: 0x204bf4e0, text: banana
[src/tokenizer.c:686] Token text freed: 0x204bf620
[src/tokenizer.c:690] Token freed: 0x204bf620 
[src/tokenizer.c:686] Token text freed: 0x204c1430
[src/tokenizer.c:690] Token freed: 0x204c1430 
[src/tokenizer.c:676] Token created: 0x204c1430, text: banana
[src/tokenizer.c:686] Token text freed: 0x204c1570
[src/tokenizer.c:690] Token freed: 0x204c1570 
[src/tokenizer.c:686] Token text freed: 0x204c3b50
[src/tokenizer.c:690] Token freed: 0x204c3b50 
[src/tokenizer.c:686] Token text freed: 0x204c57a0
[src/tokenizer.c:690] Token freed: 0x204c57a0 
[src/tokenizer.c:686] Token text freed: 0x204c5600
[src/tokenizer.c:690] Token freed: 0x204c5600 
[src/tokenizer.c:676] Token created: 0x204c5600, text: banana
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair ra n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra n
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 25 and 26
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:598] Inserting freq pair n ge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: n ge
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 19, Capacity: 300
[src/hash_table.c:274] Load factor: 0.063333
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 97 and 98
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:593] Incrementing frequency of freq pair ra n.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: n
[src/tokenizer.c:581] Next token: ge
[src/tokenizer.c:593] Incrementing frequency of freq pair n ge.
[src/tokenizer.c:576] Processing tokens: 101 and 102
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:855] Most frequent pair: n ge freq: 3
[src/tokenizer.c:676] Token created: 0x204c54a0, text: n
[src/tokenizer.c:676] Token created: 0x204c1270, text: ge
[src/tokenizer.c:676] Token created: 0x204c5640, text: nge
[src/tokenizer.c:686] Token text freed: 0x204bee70
[src/tokenizer.c:690] Token freed: 0x204bee70 
[src/tokenizer.c:676] Token created: 0x204bee70, text: nge
[src/tokenizer.c:686] Token text freed: 0x204beeb0
[src/tokenizer.c:690] Token freed: 0x204beeb0 
[src/tokenizer.c:686] Token text freed: 0x204bf370
[src/tokenizer.c:690] Token freed: 0x204bf370 
[src/tokenizer.c:676] Token created: 0x204bf370, text: nge
[src/tokenizer.c:686] Token text freed: 0x204bf3b0
[src/tokenizer.c:690] Token freed: 0x204bf3b0 
[src/tokenizer.c:686] Token text freed: 0x204c11d0
[src/tokenizer.c:690] Token freed: 0x204c11d0 
[src/tokenizer.c:676] Token created: 0x204c11d0, text: nge
[src/tokenizer.c:686] Token text freed: 0x204c1210
[src/tokenizer.c:690] Token freed: 0x204c1210 
[src/tokenizer.c:686] Token text freed: 0x204c54a0
[src/tokenizer.c:690] Token freed: 0x204c54a0 
[src/tokenizer.c:686] Token text freed: 0x204c1270
[src/tokenizer.c:690] Token freed: 0x204c1270 
[src/tokenizer.c:686] Token text freed: 0x204c5640
[src/tokenizer.c:690] Token freed: 0x204c5640 
[src/tokenizer.c:676] Token created: 0x204c5640, text: nge
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 16, Capacity: 300
[src/hash_table.c:274] Load factor: 0.053333
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: j
[src/tokenizer.c:581] Next token: o
[src/tokenizer.c:598] Inserting freq pair j o into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: j o
[src/hash_table.c:272] Current state - Size: 17, Capacity: 300
[src/hash_table.c:274] Load factor: 0.056667
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair o y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o y
[src/hash_table.c:272] Current state - Size: 18, Capacity: 300
[src/hash_table.c:274] Load factor: 0.060000
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 94 and 95
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 95 and 96
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 98 and 99
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:855] Most frequent pair: j o  freq: 1
[src/tokenizer.c:676] Token created: 0x204c4210, text: j
[src/tokenizer.c:676] Token created: 0x204c3b50, text: o
[src/tokenizer.c:676] Token created: 0x204c57a0, text: jo
[src/tokenizer.c:686] Token text freed: 0x204c0750
[src/tokenizer.c:690] Token freed: 0x204c0750 
[src/tokenizer.c:676] Token created: 0x204c0750, text: jo
[src/tokenizer.c:686] Token text freed: 0x204c0790
[src/tokenizer.c:690] Token freed: 0x204c0790 
[src/tokenizer.c:686] Token text freed: 0x204c0bb0
[src/tokenizer.c:690] Token freed: 0x204c0bb0 
[src/tokenizer.c:676] Token created: 0x204c0bb0, text: jo
[src/tokenizer.c:686] Token text freed: 0x204c0bf0
[src/tokenizer.c:690] Token freed: 0x204c0bf0 
[src/tokenizer.c:686] Token text freed: 0x204c4210
[src/tokenizer.c:690] Token freed: 0x204c4210 
[src/tokenizer.c:686] Token text freed: 0x204c3b50
[src/tokenizer.c:690] Token freed: 0x204c3b50 
[src/tokenizer.c:686] Token text freed: 0x204c57a0
[src/tokenizer.c:690] Token freed: 0x204c57a0 
[src/tokenizer.c:676] Token created: 0x204c57a0, text: jo
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 6 and 7
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair bir d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: bir d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 12 and 13
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 33 and 34
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair jo y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo y
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 15, Capacity: 300
[src/hash_table.c:274] Load factor: 0.050000
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:593] Incrementing frequency of freq pair jo y.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 86 and 87
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 89 and 90
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 92 and 93
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 93 and 94
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 96 and 97
[src/tokenizer.c:578] Current token: bir
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair bir d.
[src/tokenizer.c:855] Most frequent pair: bir d freq: 3
[src/tokenizer.c:676] Token created: 0x204c3c10, text: bir
[src/tokenizer.c:676] Token created: 0x204c5a80, text: d
[src/tokenizer.c:676] Token created: 0x204c05d0, text: bird
[src/tokenizer.c:686] Token text freed: 0x204bae10
[src/tokenizer.c:690] Token freed: 0x204bae10 
[src/tokenizer.c:676] Token created: 0x204bae10, text: bird
[src/tokenizer.c:686] Token text freed: 0x204be3c0
[src/tokenizer.c:690] Token freed: 0x204be3c0 
[src/tokenizer.c:686] Token text freed: 0x204bce00
[src/tokenizer.c:690] Token freed: 0x204bce00 
[src/tokenizer.c:676] Token created: 0x204bce00, text: bird
[src/tokenizer.c:686] Token text freed: 0x204beb10
[src/tokenizer.c:690] Token freed: 0x204beb10 
[src/tokenizer.c:686] Token text freed: 0x204c12b0
[src/tokenizer.c:690] Token freed: 0x204c12b0 
[src/tokenizer.c:676] Token created: 0x204c12b0, text: bird
[src/tokenizer.c:686] Token text freed: 0x204c1350
[src/tokenizer.c:690] Token freed: 0x204c1350 
[src/tokenizer.c:686] Token text freed: 0x204c3c10
[src/tokenizer.c:690] Token freed: 0x204c3c10 
[src/tokenizer.c:686] Token text freed: 0x204c5a80
[src/tokenizer.c:690] Token freed: 0x204c5a80 
[src/tokenizer.c:686] Token text freed: 0x204c05d0
[src/tokenizer.c:690] Token freed: 0x204c05d0 
[src/tokenizer.c:676] Token created: 0x204c05d0, text: bird
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 11 and 12
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:598] Inserting freq pair ap p into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap p
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:598] Inserting freq pair p le into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: p le
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 22 and 23
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 31 and 32
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair jo y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo y
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 14, Capacity: 300
[src/hash_table.c:274] Load factor: 0.046667
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:593] Incrementing frequency of freq pair jo y.
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: p
[src/tokenizer.c:593] Incrementing frequency of freq pair ap p.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: p
[src/tokenizer.c:581] Next token: le
[src/tokenizer.c:593] Incrementing frequency of freq pair p le.
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 90 and 91
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 91 and 92
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:855] Most frequent pair: p le freq: 3
[src/tokenizer.c:676] Token created: 0x204c5b80, text: p
[src/tokenizer.c:676] Token created: 0x204bf580, text: le
[src/tokenizer.c:676] Token created: 0x204c4310, text: ple
[src/tokenizer.c:686] Token text freed: 0x204bec90
[src/tokenizer.c:690] Token freed: 0x204bec90 
[src/tokenizer.c:676] Token created: 0x204bec90, text: ple
[src/tokenizer.c:686] Token text freed: 0x204becd0
[src/tokenizer.c:690] Token freed: 0x204becd0 
[src/tokenizer.c:686] Token text freed: 0x204bf190
[src/tokenizer.c:690] Token freed: 0x204bf190 
[src/tokenizer.c:676] Token created: 0x204bf190, text: ple
[src/tokenizer.c:686] Token text freed: 0x204bf1d0
[src/tokenizer.c:690] Token freed: 0x204bf1d0 
[src/tokenizer.c:686] Token text freed: 0x204c0ef0
[src/tokenizer.c:690] Token freed: 0x204c0ef0 
[src/tokenizer.c:676] Token created: 0x204c0ef0, text: ple
[src/tokenizer.c:686] Token text freed: 0x204c0f30
[src/tokenizer.c:690] Token freed: 0x204c0f30 
[src/tokenizer.c:686] Token text freed: 0x204c5b80
[src/tokenizer.c:690] Token freed: 0x204c5b80 
[src/tokenizer.c:686] Token text freed: 0x204bf580
[src/tokenizer.c:690] Token freed: 0x204bf580 
[src/tokenizer.c:686] Token text freed: 0x204c4310
[src/tokenizer.c:690] Token freed: 0x204c4310 
[src/tokenizer.c:676] Token created: 0x204c4310, text: ple
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 3 and 4
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:598] Inserting freq pair do g into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: do g
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 8 and 9
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 11 and 12
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 20 and 21
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 21 and 22
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 29 and 30
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 42 and 43
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair jo y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo y
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 13, Capacity: 300
[src/hash_table.c:274] Load factor: 0.043333
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:593] Incrementing frequency of freq pair jo y.
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: do
[src/tokenizer.c:581] Next token: g
[src/tokenizer.c:593] Incrementing frequency of freq pair do g.
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 87 and 88
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 88 and 89
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:855] Most frequent pair: do g freq: 3
[src/tokenizer.c:676] Token created: 0x204bfaa0, text: do
[src/tokenizer.c:676] Token created: 0x204c3c10, text: g
[src/tokenizer.c:676] Token created: 0x204c5a80, text: dog
[src/tokenizer.c:686] Token text freed: 0x204be5a0
[src/tokenizer.c:690] Token freed: 0x204be5a0 
[src/tokenizer.c:676] Token created: 0x204be5a0, text: dog
[src/tokenizer.c:686] Token text freed: 0x204be5e0
[src/tokenizer.c:690] Token freed: 0x204be5e0 
[src/tokenizer.c:686] Token text freed: 0x204be480
[src/tokenizer.c:690] Token freed: 0x204be480 
[src/tokenizer.c:676] Token created: 0x204be480, text: dog
[src/tokenizer.c:686] Token text freed: 0x204be500
[src/tokenizer.c:690] Token freed: 0x204be500 
[src/tokenizer.c:686] Token text freed: 0x204c0d90
[src/tokenizer.c:690] Token freed: 0x204c0d90 
[src/tokenizer.c:676] Token created: 0x204c0d90, text: dog
[src/tokenizer.c:686] Token text freed: 0x204c0dd0
[src/tokenizer.c:690] Token freed: 0x204c0dd0 
[src/tokenizer.c:686] Token text freed: 0x204bfaa0
[src/tokenizer.c:690] Token freed: 0x204bfaa0 
[src/tokenizer.c:686] Token text freed: 0x204c3c10
[src/tokenizer.c:690] Token freed: 0x204c3c10 
[src/tokenizer.c:686] Token text freed: 0x204c5a80
[src/tokenizer.c:690] Token freed: 0x204c5a80 
[src/tokenizer.c:676] Token created: 0x204c5a80, text: dog
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:598] Inserting freq pair jo y into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo y
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:598] Inserting freq pair y ful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: y ful
[src/hash_table.c:272] Current state - Size: 12, Capacity: 300
[src/hash_table.c:274] Load factor: 0.040000
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: y
[src/tokenizer.c:593] Incrementing frequency of freq pair jo y.
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: y
[src/tokenizer.c:581] Next token: ful
[src/tokenizer.c:593] Incrementing frequency of freq pair y ful.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 81 and 82
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 84 and 85
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 85 and 86
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:855] Most frequent pair: y ful freq: 2
[src/tokenizer.c:676] Token created: 0x204c41d0, text: y
[src/tokenizer.c:676] Token created: 0x204c5b80, text: ful
[src/tokenizer.c:676] Token created: 0x204bf580, text: yful
[src/tokenizer.c:686] Token text freed: 0x204c07d0
[src/tokenizer.c:690] Token freed: 0x204c07d0 
[src/tokenizer.c:676] Token created: 0x204c07d0, text: yful
[src/tokenizer.c:686] Token text freed: 0x204c0810
[src/tokenizer.c:690] Token freed: 0x204c0810 
[src/tokenizer.c:686] Token text freed: 0x204c0c30
[src/tokenizer.c:690] Token freed: 0x204c0c30 
[src/tokenizer.c:676] Token created: 0x204c0c30, text: yful
[src/tokenizer.c:686] Token text freed: 0x204c0c70
[src/tokenizer.c:690] Token freed: 0x204c0c70 
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:686] Token text freed: 0x204c5b80
[src/tokenizer.c:690] Token freed: 0x204c5b80 
[src/tokenizer.c:686] Token text freed: 0x204bf580
[src/tokenizer.c:690] Token freed: 0x204bf580 
[src/tokenizer.c:676] Token created: 0x204bf580, text: yful
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:598] Inserting freq pair o ra into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o ra
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 19 and 20
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:598] Inserting freq pair ra nge into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ra nge
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 27 and 28
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 28 and 29
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 50 and 51
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 55 and 56
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 61 and 62
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:598] Inserting freq pair jo yful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo yful
[src/hash_table.c:272] Current state - Size: 11, Capacity: 300
[src/hash_table.c:274] Load factor: 0.036667
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:593] Incrementing frequency of freq pair jo yful.
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 79 and 80
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 82 and 83
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: ra
[src/tokenizer.c:593] Incrementing frequency of freq pair o ra.
[src/tokenizer.c:576] Processing tokens: 83 and 84
[src/tokenizer.c:578] Current token: ra
[src/tokenizer.c:581] Next token: nge
[src/tokenizer.c:593] Incrementing frequency of freq pair ra nge.
[src/tokenizer.c:855] Most frequent pair: ra nge freq: 3
[src/tokenizer.c:676] Token created: 0x204c0ad0, text: ra
[src/tokenizer.c:676] Token created: 0x204bfaa0, text: nge
[src/tokenizer.c:676] Token created: 0x204c3c10, text: range
[src/tokenizer.c:686] Token text freed: 0x204bedf0
[src/tokenizer.c:690] Token freed: 0x204bedf0 
[src/tokenizer.c:676] Token created: 0x204bedf0, text: range
[src/tokenizer.c:686] Token text freed: 0x204bee70
[src/tokenizer.c:690] Token freed: 0x204bee70 
[src/tokenizer.c:686] Token text freed: 0x204bf2f0
[src/tokenizer.c:690] Token freed: 0x204bf2f0 
[src/tokenizer.c:676] Token created: 0x204bf2f0, text: range
[src/tokenizer.c:686] Token text freed: 0x204bf370
[src/tokenizer.c:690] Token freed: 0x204bf370 
[src/tokenizer.c:686] Token text freed: 0x204c1150
[src/tokenizer.c:690] Token freed: 0x204c1150 
[src/tokenizer.c:676] Token created: 0x204c1150, text: range
[src/tokenizer.c:686] Token text freed: 0x204c11d0
[src/tokenizer.c:690] Token freed: 0x204c11d0 
[src/tokenizer.c:686] Token text freed: 0x204c0ad0
[src/tokenizer.c:690] Token freed: 0x204c0ad0 
[src/tokenizer.c:686] Token text freed: 0x204bfaa0
[src/tokenizer.c:690] Token freed: 0x204bfaa0 
[src/tokenizer.c:686] Token text freed: 0x204c3c10
[src/tokenizer.c:690] Token freed: 0x204c3c10 
[src/tokenizer.c:676] Token created: 0x204c3c10, text: range
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:598] Inserting freq pair re e into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re e
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 48 and 49
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: e
[src/tokenizer.c:593] Incrementing frequency of freq pair re e.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: e
[src/tokenizer.c:581] Next token: n
[src/tokenizer.c:598] Inserting freq pair e n into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: e n
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 53 and 54
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 9, Capacity: 300
[src/hash_table.c:274] Load factor: 0.030000
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:598] Inserting freq pair jo yful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo yful
[src/hash_table.c:272] Current state - Size: 10, Capacity: 300
[src/hash_table.c:274] Load factor: 0.033333
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 65 and 66
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:593] Incrementing frequency of freq pair jo yful.
[src/tokenizer.c:576] Processing tokens: 74 and 75
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 77 and 78
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 80 and 81
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: e n  freq: 1
[src/tokenizer.c:676] Token created: 0x204bfd60, text: e
[src/tokenizer.c:676] Token created: 0x204c41d0, text: n
[src/tokenizer.c:676] Token created: 0x204c5b80, text: en
[src/tokenizer.c:686] Token text freed: 0x204bf9a0
[src/tokenizer.c:690] Token freed: 0x204bf9a0 
[src/tokenizer.c:676] Token created: 0x204bf9a0, text: en
[src/tokenizer.c:686] Token text freed: 0x204bf9e0
[src/tokenizer.c:690] Token freed: 0x204bf9e0 
[src/tokenizer.c:686] Token text freed: 0x204bfd80
[src/tokenizer.c:690] Token freed: 0x204bfd80 
[src/tokenizer.c:676] Token created: 0x204bfd80, text: en
[src/tokenizer.c:686] Token text freed: 0x204bfdc0
[src/tokenizer.c:690] Token freed: 0x204bfdc0 
[src/tokenizer.c:686] Token text freed: 0x204bfd60
[src/tokenizer.c:690] Token freed: 0x204bfd60 
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:686] Token text freed: 0x204c5b80
[src/tokenizer.c:690] Token freed: 0x204c5b80 
[src/tokenizer.c:676] Token created: 0x204c5b80, text: en
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair re en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re en
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair re en.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:598] Inserting freq pair jo yful into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: jo yful
[src/hash_table.c:272] Current state - Size: 8, Capacity: 300
[src/hash_table.c:274] Load factor: 0.026667
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 63 and 64
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: jo
[src/tokenizer.c:581] Next token: yful
[src/tokenizer.c:593] Incrementing frequency of freq pair jo yful.
[src/tokenizer.c:576] Processing tokens: 72 and 73
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 75 and 76
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 78 and 79
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: jo yful freq: 2
[src/tokenizer.c:676] Token created: 0x204c5280, text: jo
[src/tokenizer.c:676] Token created: 0x204c1370, text: yful
[src/tokenizer.c:676] Token created: 0x204c0ad0, text: joyful
[src/tokenizer.c:686] Token text freed: 0x204c0750
[src/tokenizer.c:690] Token freed: 0x204c0750 
[src/tokenizer.c:676] Token created: 0x204c0750, text: joyful
[src/tokenizer.c:686] Token text freed: 0x204c07d0
[src/tokenizer.c:690] Token freed: 0x204c07d0 
[src/tokenizer.c:686] Token text freed: 0x204c0bb0
[src/tokenizer.c:690] Token freed: 0x204c0bb0 
[src/tokenizer.c:676] Token created: 0x204c0bb0, text: joyful
[src/tokenizer.c:686] Token text freed: 0x204c0c30
[src/tokenizer.c:690] Token freed: 0x204c0c30 
[src/tokenizer.c:686] Token text freed: 0x204c5280
[src/tokenizer.c:690] Token freed: 0x204c5280 
[src/tokenizer.c:686] Token text freed: 0x204c1370
[src/tokenizer.c:690] Token freed: 0x204c1370 
[src/tokenizer.c:686] Token text freed: 0x204c0ad0
[src/tokenizer.c:690] Token freed: 0x204c0ad0 
[src/tokenizer.c:676] Token created: 0x204c0ad0, text: joyful
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 15 and 16
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:598] Inserting freq pair ap ple into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: ap ple
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 18 and 19
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 23 and 24
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 26 and 27
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 38 and 39
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair re en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re en
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 46 and 47
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair re en.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 7, Capacity: 300
[src/hash_table.c:274] Load factor: 0.023333
[src/tokenizer.c:576] Processing tokens: 59 and 60
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: ap
[src/tokenizer.c:581] Next token: ple
[src/tokenizer.c:593] Incrementing frequency of freq pair ap ple.
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 76 and 77
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: ap ple freq: 3
[src/tokenizer.c:676] Token created: 0x204c5240, text: ap
[src/tokenizer.c:676] Token created: 0x204c41d0, text: ple
[src/tokenizer.c:676] Token created: 0x204bf410, text: apple
[src/tokenizer.c:686] Token text freed: 0x204bec10
[src/tokenizer.c:690] Token freed: 0x204bec10 
[src/tokenizer.c:676] Token created: 0x204bec10, text: apple
[src/tokenizer.c:686] Token text freed: 0x204bec90
[src/tokenizer.c:690] Token freed: 0x204bec90 
[src/tokenizer.c:686] Token text freed: 0x204bf110
[src/tokenizer.c:690] Token freed: 0x204bf110 
[src/tokenizer.c:676] Token created: 0x204bf110, text: apple
[src/tokenizer.c:686] Token text freed: 0x204bf190
[src/tokenizer.c:690] Token freed: 0x204bf190 
[src/tokenizer.c:686] Token text freed: 0x204c0e70
[src/tokenizer.c:690] Token freed: 0x204c0e70 
[src/tokenizer.c:676] Token created: 0x204c0e70, text: apple
[src/tokenizer.c:686] Token text freed: 0x204c0ef0
[src/tokenizer.c:690] Token freed: 0x204c0ef0 
[src/tokenizer.c:686] Token text freed: 0x204c5240
[src/tokenizer.c:690] Token freed: 0x204c5240 
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:686] Token text freed: 0x204bf410
[src/tokenizer.c:690] Token freed: 0x204bf410 
[src/tokenizer.c:676] Token created: 0x204bf410, text: apple
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair re en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re en
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair re en.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:598] Inserting freq pair h appy into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: h appy
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 6, Capacity: 300
[src/hash_table.c:274] Load factor: 0.020000
[src/tokenizer.c:576] Processing tokens: 57 and 58
[src/tokenizer.c:578] Current token: h
[src/tokenizer.c:581] Next token: appy
[src/tokenizer.c:593] Incrementing frequency of freq pair h appy.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 70 and 71
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 73 and 74
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: h appy freq: 2
[src/tokenizer.c:676] Token created: 0x204bf760, text: h
[src/tokenizer.c:676] Token created: 0x204c5280, text: appy
[src/tokenizer.c:676] Token created: 0x204c1370, text: happy
[src/tokenizer.c:686] Token text freed: 0x204bfe60
[src/tokenizer.c:690] Token freed: 0x204bfe60 
[src/tokenizer.c:676] Token created: 0x204bfe60, text: happy
[src/tokenizer.c:686] Token text freed: 0x204bfea0
[src/tokenizer.c:690] Token freed: 0x204bfea0 
[src/tokenizer.c:686] Token text freed: 0x204c08f0
[src/tokenizer.c:690] Token freed: 0x204c08f0 
[src/tokenizer.c:676] Token created: 0x204c08f0, text: happy
[src/tokenizer.c:686] Token text freed: 0x204c0930
[src/tokenizer.c:690] Token freed: 0x204c0930 
[src/tokenizer.c:686] Token text freed: 0x204bf760
[src/tokenizer.c:690] Token freed: 0x204bf760 
[src/tokenizer.c:686] Token text freed: 0x204c5280
[src/tokenizer.c:690] Token freed: 0x204c5280 
[src/tokenizer.c:686] Token text freed: 0x204c1370
[src/tokenizer.c:690] Token freed: 0x204c1370 
[src/tokenizer.c:676] Token created: 0x204c1370, text: happy
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:598] Inserting freq pair g re into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: g re
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 36 and 37
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair re en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re en
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 44 and 45
[src/tokenizer.c:578] Current token: g
[src/tokenizer.c:581] Next token: re
[src/tokenizer.c:593] Incrementing frequency of freq pair g re.
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair re en.
[src/tokenizer.c:576] Processing tokens: 51 and 52
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 5, Capacity: 300
[src/hash_table.c:274] Load factor: 0.016667
[src/tokenizer.c:576] Processing tokens: 58 and 59
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 68 and 69
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 71 and 72
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: g re freq: 2
[src/tokenizer.c:676] Token created: 0x204c1590, text: g
[src/tokenizer.c:676] Token created: 0x204c5240, text: re
[src/tokenizer.c:676] Token created: 0x204c41d0, text: gre
[src/tokenizer.c:686] Token text freed: 0x204bf8e0
[src/tokenizer.c:690] Token freed: 0x204bf8e0 
[src/tokenizer.c:676] Token created: 0x204bf8e0, text: gre
[src/tokenizer.c:686] Token text freed: 0x204bf920
[src/tokenizer.c:690] Token freed: 0x204bf920 
[src/tokenizer.c:686] Token text freed: 0x204bfcc0
[src/tokenizer.c:690] Token freed: 0x204bfcc0 
[src/tokenizer.c:676] Token created: 0x204bfcc0, text: gre
[src/tokenizer.c:686] Token text freed: 0x204bfd00
[src/tokenizer.c:690] Token freed: 0x204bfd00 
[src/tokenizer.c:686] Token text freed: 0x204c1590
[src/tokenizer.c:690] Token freed: 0x204c1590 
[src/tokenizer.c:686] Token text freed: 0x204c5240
[src/tokenizer.c:690] Token freed: 0x204c5240 
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:676] Token created: 0x204c41d0, text: gre
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:598] Inserting freq pair re d into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: re d
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 35 and 36
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair gre en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: gre en
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 40 and 41
[src/tokenizer.c:578] Current token: re
[src/tokenizer.c:581] Next token: d
[src/tokenizer.c:593] Incrementing frequency of freq pair re d.
[src/tokenizer.c:576] Processing tokens: 43 and 44
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair gre en.
[src/tokenizer.c:576] Processing tokens: 49 and 50
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 4, Capacity: 300
[src/hash_table.c:274] Load factor: 0.013333
[src/tokenizer.c:576] Processing tokens: 56 and 57
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 66 and 67
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 69 and 70
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: re d freq: 2
[src/tokenizer.c:676] Token created: 0x204c3c90, text: re
[src/tokenizer.c:676] Token created: 0x204bf760, text: d
[src/tokenizer.c:676] Token created: 0x204c5280, text: red
[src/tokenizer.c:686] Token text freed: 0x204bf7a0
[src/tokenizer.c:690] Token freed: 0x204bf7a0 
[src/tokenizer.c:676] Token created: 0x204bf7a0, text: red
[src/tokenizer.c:686] Token text freed: 0x204bf820
[src/tokenizer.c:690] Token freed: 0x204bf820 
[src/tokenizer.c:686] Token text freed: 0x204bfb60
[src/tokenizer.c:690] Token freed: 0x204bfb60 
[src/tokenizer.c:676] Token created: 0x204bfb60, text: red
[src/tokenizer.c:686] Token text freed: 0x204bfbe0
[src/tokenizer.c:690] Token freed: 0x204bfbe0 
[src/tokenizer.c:686] Token text freed: 0x204c3c90
[src/tokenizer.c:690] Token freed: 0x204c3c90 
[src/tokenizer.c:686] Token text freed: 0x204bf760
[src/tokenizer.c:690] Token freed: 0x204bf760 
[src/tokenizer.c:686] Token text freed: 0x204c5280
[src/tokenizer.c:690] Token freed: 0x204c5280 
[src/tokenizer.c:676] Token created: 0x204c5280, text: red
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 17 and 18
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:598] Inserting freq pair o range into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: o range
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 24 and 25
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:576] Processing tokens: 34 and 35
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair gre en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: gre en
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 41 and 42
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair gre en.
[src/tokenizer.c:576] Processing tokens: 47 and 48
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 3, Capacity: 300
[src/hash_table.c:274] Load factor: 0.010000
[src/tokenizer.c:576] Processing tokens: 54 and 55
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 64 and 65
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 67 and 68
[src/tokenizer.c:578] Current token: o
[src/tokenizer.c:581] Next token: range
[src/tokenizer.c:593] Incrementing frequency of freq pair o range.
[src/tokenizer.c:855] Most frequent pair: o range freq: 3
[src/tokenizer.c:676] Token created: 0x204c59c0, text: o
[src/tokenizer.c:676] Token created: 0x204c1590, text: range
[src/tokenizer.c:676] Token created: 0x204c5240, text: orange
[src/tokenizer.c:686] Token text freed: 0x204bedb0
[src/tokenizer.c:690] Token freed: 0x204bedb0 
[src/tokenizer.c:676] Token created: 0x204bedb0, text: orange
[src/tokenizer.c:686] Token text freed: 0x204bedf0
[src/tokenizer.c:690] Token freed: 0x204bedf0 
[src/tokenizer.c:686] Token text freed: 0x204bf2b0
[src/tokenizer.c:690] Token freed: 0x204bf2b0 
[src/tokenizer.c:676] Token created: 0x204bf2b0, text: orange
[src/tokenizer.c:686] Token text freed: 0x204bf2f0
[src/tokenizer.c:690] Token freed: 0x204bf2f0 
[src/tokenizer.c:686] Token text freed: 0x204c1110
[src/tokenizer.c:690] Token freed: 0x204c1110 
[src/tokenizer.c:676] Token created: 0x204c1110, text: orange
[src/tokenizer.c:686] Token text freed: 0x204c1150
[src/tokenizer.c:690] Token freed: 0x204c1150 
[src/tokenizer.c:686] Token text freed: 0x204c59c0
[src/tokenizer.c:690] Token freed: 0x204c59c0 
[src/tokenizer.c:686] Token text freed: 0x204c1590
[src/tokenizer.c:690] Token freed: 0x204c1590 
[src/tokenizer.c:686] Token text freed: 0x204c5240
[src/tokenizer.c:690] Token freed: 0x204c5240 
[src/tokenizer.c:676] Token created: 0x204c5240, text: orange
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair gre en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: gre en
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair gre en.
[src/tokenizer.c:576] Processing tokens: 45 and 46
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:598] Inserting freq pair s ad into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: s ad
[src/hash_table.c:272] Current state - Size: 2, Capacity: 300
[src/hash_table.c:274] Load factor: 0.006667
[src/tokenizer.c:576] Processing tokens: 52 and 53
[src/tokenizer.c:578] Current token: s
[src/tokenizer.c:581] Next token: ad
[src/tokenizer.c:593] Incrementing frequency of freq pair s ad.
[src/tokenizer.c:576] Processing tokens: 62 and 63
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:855] Most frequent pair: s ad freq: 2
[src/tokenizer.c:676] Token created: 0x204bfc00, text: s
[src/tokenizer.c:676] Token created: 0x204c3c90, text: ad
[src/tokenizer.c:676] Token created: 0x204bf760, text: sad
[src/tokenizer.c:686] Token text freed: 0x204c0610
[src/tokenizer.c:690] Token freed: 0x204c0610 
[src/tokenizer.c:676] Token created: 0x204c0610, text: sad
[src/tokenizer.c:686] Token text freed: 0x204c0630
[src/tokenizer.c:690] Token freed: 0x204c0630 
[src/tokenizer.c:686] Token text freed: 0x204c0a50
[src/tokenizer.c:690] Token freed: 0x204c0a50 
[src/tokenizer.c:676] Token created: 0x204c0a50, text: sad
[src/tokenizer.c:686] Token text freed: 0x204c0a70
[src/tokenizer.c:690] Token freed: 0x204c0a70 
[src/tokenizer.c:686] Token text freed: 0x204bfc00
[src/tokenizer.c:690] Token freed: 0x204bfc00 
[src/tokenizer.c:686] Token text freed: 0x204c3c90
[src/tokenizer.c:690] Token freed: 0x204c3c90 
[src/tokenizer.c:686] Token text freed: 0x204bf760
[src/tokenizer.c:690] Token freed: 0x204bf760 
[src/tokenizer.c:676] Token created: 0x204bf760, text: sad
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 0 and 1
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:598] Inserting freq pair c at into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: c at
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 9 and 10
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:576] Processing tokens: 32 and 33
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair gre en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: gre en
[src/hash_table.c:272] Current state - Size: 1, Capacity: 300
[src/hash_table.c:274] Load factor: 0.003333
[src/tokenizer.c:576] Processing tokens: 39 and 40
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair gre en.
[src/tokenizer.c:576] Processing tokens: 60 and 61
[src/tokenizer.c:578] Current token: c
[src/tokenizer.c:581] Next token: at
[src/tokenizer.c:593] Incrementing frequency of freq pair c at.
[src/tokenizer.c:855] Most frequent pair: c at freq: 3
[src/tokenizer.c:676] Token created: 0x204c3b70, text: c
[src/tokenizer.c:676] Token created: 0x204c59c0, text: at
[src/tokenizer.c:676] Token created: 0x204c1590, text: cat
[src/tokenizer.c:686] Token text freed: 0x204ca4f0
[src/tokenizer.c:690] Token freed: 0x204ca4f0 
[src/tokenizer.c:676] Token created: 0x204ca4f0, text: cat
[src/tokenizer.c:686] Token text freed: 0x204baf40
[src/tokenizer.c:690] Token freed: 0x204baf40 
[src/tokenizer.c:686] Token text freed: 0x204bcc80
[src/tokenizer.c:690] Token freed: 0x204bcc80 
[src/tokenizer.c:676] Token created: 0x204bcc80, text: cat
[src/tokenizer.c:686] Token text freed: 0x204bccc0
[src/tokenizer.c:690] Token freed: 0x204bccc0 
[src/tokenizer.c:686] Token text freed: 0x204c0fd0
[src/tokenizer.c:690] Token freed: 0x204c0fd0 
[src/tokenizer.c:676] Token created: 0x204c0fd0, text: cat
[src/tokenizer.c:686] Token text freed: 0x204c0ff0
[src/tokenizer.c:690] Token freed: 0x204c0ff0 
[src/tokenizer.c:686] Token text freed: 0x204c3b70
[src/tokenizer.c:690] Token freed: 0x204c3b70 
[src/tokenizer.c:686] Token text freed: 0x204c59c0
[src/tokenizer.c:690] Token freed: 0x204c59c0 
[src/tokenizer.c:686] Token text freed: 0x204c1590
[src/tokenizer.c:690] Token freed: 0x204c1590 
[src/tokenizer.c:676] Token created: 0x204c1590, text: cat
[src/tokenizer.c:849] Counting pairs...
[src/tokenizer.c:576] Processing tokens: 30 and 31
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:598] Inserting freq pair gre en into the hash table if you see this multiple time for the same token then get_value did not work as expected.
[src/hash_table.c:270] Insert attempt - Key: gre en
[src/hash_table.c:272] Current state - Size: 0, Capacity: 300
[src/hash_table.c:274] Load factor: 0.000000
[src/tokenizer.c:576] Processing tokens: 37 and 38
[src/tokenizer.c:578] Current token: gre
[src/tokenizer.c:581] Next token: en
[src/tokenizer.c:593] Incrementing frequency of freq pair gre en.
[src/tokenizer.c:855] Most frequent pair: gre en freq: 2
[src/tokenizer.c:676] Token created: 0x204c0690, text: gre
[src/tokenizer.c:676] Token created: 0x204bfc00, text: en
[src/tokenizer.c:676] Token created: 0x204c3c90, text: green
[src/tokenizer.c:686] Token text freed: 0x204bf8e0
[src/tokenizer.c:690] Token freed: 0x204bf8e0 
[src/tokenizer.c:676] Token created: 0x204bf8e0, text: green
[src/tokenizer.c:686] Token text freed: 0x204bf9a0
[src/tokenizer.c:690] Token freed: 0x204bf9a0 
[src/tokenizer.c:686] Token text freed: 0x204bfcc0
[src/tokenizer.c:690] Token freed: 0x204bfcc0 
[src/tokenizer.c:676] Token created: 0x204bfcc0, text: green
[src/tokenizer.c:686] Token text freed: 0x204bfd80
[src/tokenizer.c:690] Token freed: 0x204bfd80 
[src/tokenizer.c:686] Token text freed: 0x204c0690
[src/tokenizer.c:690] Token freed: 0x204c0690 
[src/tokenizer.c:686] Token text freed: 0x204bfc00
[src/tokenizer.c:690] Token freed: 0x204bfc00 
[src/tokenizer.c:686] Token text freed: 0x204c3c90
[src/tokenizer.c:690] Token freed: 0x204c3c90 
[src/tokenizer.c:676] Token created: 0x204c3c90, text: green
[src/tokenizer.c:849] Counting pairs...
No entry in hash table.
[src/tokenizer.c:686] Token text freed: 0x204ca4f0
[src/tokenizer.c:690] Token freed: 0x204ca4f0 
[src/tokenizer.c:686] Token text freed: 0x204baf80
[src/tokenizer.c:690] Token freed: 0x204baf80 
[src/tokenizer.c:686] Token text freed: 0x204be5a0
[src/tokenizer.c:690] Token freed: 0x204be5a0 
[src/tokenizer.c:686] Token text freed: 0x204be600
[src/tokenizer.c:690] Token freed: 0x204be600 
[src/tokenizer.c:686] Token text freed: 0x204bae10
[src/tokenizer.c:690] Token freed: 0x204bae10 
[src/tokenizer.c:686] Token text freed: 0x204be460
[src/tokenizer.c:690] Token freed: 0x204be460 
[src/tokenizer.c:686] Token text freed: 0x204be480
[src/tokenizer.c:690] Token freed: 0x204be480 
[src/tokenizer.c:686] Token text freed: 0x204bcc40
[src/tokenizer.c:690] Token freed: 0x204bcc40 
[src/tokenizer.c:686] Token text freed: 0x204bcc80
[src/tokenizer.c:690] Token freed: 0x204bcc80 
[src/tokenizer.c:686] Token text freed: 0x204bcd40
[src/tokenizer.c:690] Token freed: 0x204bcd40 
[src/tokenizer.c:686] Token text freed: 0x204bce00
[src/tokenizer.c:690] Token freed: 0x204bce00 
[src/tokenizer.c:686] Token text freed: 0x204beb50
[src/tokenizer.c:690] Token freed: 0x204beb50 
[src/tokenizer.c:686] Token text freed: 0x204beb90
[src/tokenizer.c:690] Token freed: 0x204beb90 
[src/tokenizer.c:686] Token text freed: 0x204bec10
[src/tokenizer.c:690] Token freed: 0x204bec10 
[src/tokenizer.c:686] Token text freed: 0x204bed50
[src/tokenizer.c:690] Token freed: 0x204bed50 
[src/tokenizer.c:686] Token text freed: 0x204bedb0
[src/tokenizer.c:690] Token freed: 0x204bedb0 
[src/tokenizer.c:686] Token text freed: 0x204bef30
[src/tokenizer.c:690] Token freed: 0x204bef30 
[src/tokenizer.c:686] Token text freed: 0x204bef70
[src/tokenizer.c:690] Token freed: 0x204bef70 
[src/tokenizer.c:686] Token text freed: 0x204bf0f0
[src/tokenizer.c:690] Token freed: 0x204bf0f0 
[src/tokenizer.c:686] Token text freed: 0x204bf110
[src/tokenizer.c:690] Token freed: 0x204bf110 
[src/tokenizer.c:686] Token text freed: 0x204bf250
[src/tokenizer.c:690] Token freed: 0x204bf250 
[src/tokenizer.c:686] Token text freed: 0x204bf2b0
[src/tokenizer.c:690] Token freed: 0x204bf2b0 
[src/tokenizer.c:686] Token text freed: 0x204bf430
[src/tokenizer.c:690] Token freed: 0x204bf430 
[src/tokenizer.c:686] Token text freed: 0x204bf4e0
[src/tokenizer.c:690] Token freed: 0x204bf4e0 
[src/tokenizer.c:686] Token text freed: 0x204bf660
[src/tokenizer.c:690] Token freed: 0x204bf660 
[src/tokenizer.c:686] Token text freed: 0x204bf6a0
[src/tokenizer.c:690] Token freed: 0x204bf6a0 
[src/tokenizer.c:686] Token text freed: 0x204bf6c0
[src/tokenizer.c:690] Token freed: 0x204bf6c0 
[src/tokenizer.c:686] Token text freed: 0x204bf780
[src/tokenizer.c:690] Token freed: 0x204bf780 
[src/tokenizer.c:686] Token text freed: 0x204bf7a0
[src/tokenizer.c:690] Token freed: 0x204bf7a0 
[src/tokenizer.c:686] Token text freed: 0x204bf860
[src/tokenizer.c:690] Token freed: 0x204bf860 
[src/tokenizer.c:686] Token text freed: 0x204bf8e0
[src/tokenizer.c:690] Token freed: 0x204bf8e0 
[src/tokenizer.c:686] Token text freed: 0x204bfa20
[src/tokenizer.c:690] Token freed: 0x204bfa20 
[src/tokenizer.c:686] Token text freed: 0x204bfa40
[src/tokenizer.c:690] Token freed: 0x204bfa40 
[src/tokenizer.c:686] Token text freed: 0x204bfb40
[src/tokenizer.c:690] Token freed: 0x204bfb40 
[src/tokenizer.c:686] Token text freed: 0x204bfb60
[src/tokenizer.c:690] Token freed: 0x204bfb60 
[src/tokenizer.c:686] Token text freed: 0x204bfc20
[src/tokenizer.c:690] Token freed: 0x204bfc20 
[src/tokenizer.c:686] Token text freed: 0x204bfcc0
[src/tokenizer.c:690] Token freed: 0x204bfcc0 
[src/tokenizer.c:686] Token text freed: 0x204bfe00
[src/tokenizer.c:690] Token freed: 0x204bfe00 
[src/tokenizer.c:686] Token text freed: 0x204bfe40
[src/tokenizer.c:690] Token freed: 0x204bfe40 
[src/tokenizer.c:686] Token text freed: 0x204bfe60
[src/tokenizer.c:690] Token freed: 0x204bfe60 
[src/tokenizer.c:686] Token text freed: 0x204c05f0
[src/tokenizer.c:690] Token freed: 0x204c05f0 
[src/tokenizer.c:686] Token text freed: 0x204c0610
[src/tokenizer.c:690] Token freed: 0x204c0610 
[src/tokenizer.c:686] Token text freed: 0x204c06b0
[src/tokenizer.c:690] Token freed: 0x204c06b0 
[src/tokenizer.c:686] Token text freed: 0x204c0750
[src/tokenizer.c:690] Token freed: 0x204c0750 
[src/tokenizer.c:686] Token text freed: 0x204c08d0
[src/tokenizer.c:690] Token freed: 0x204c08d0 
[src/tokenizer.c:686] Token text freed: 0x204c08f0
[src/tokenizer.c:690] Token freed: 0x204c08f0 
[src/tokenizer.c:686] Token text freed: 0x204c0a30
[src/tokenizer.c:690] Token freed: 0x204c0a30 
[src/tokenizer.c:686] Token text freed: 0x204c0a50
[src/tokenizer.c:690] Token freed: 0x204c0a50 
[src/tokenizer.c:686] Token text freed: 0x204c0af0
[src/tokenizer.c:690] Token freed: 0x204c0af0 
[src/tokenizer.c:686] Token text freed: 0x204c0bb0
[src/tokenizer.c:690] Token freed: 0x204c0bb0 
[src/tokenizer.c:686] Token text freed: 0x204c0d30
[src/tokenizer.c:690] Token freed: 0x204c0d30 
[src/tokenizer.c:686] Token text freed: 0x204c0d70
[src/tokenizer.c:690] Token freed: 0x204c0d70 
[src/tokenizer.c:686] Token text freed: 0x204c0d90
[src/tokenizer.c:690] Token freed: 0x204c0d90 
[src/tokenizer.c:686] Token text freed: 0x204c0df0
[src/tokenizer.c:690] Token freed: 0x204c0df0 
[src/tokenizer.c:686] Token text freed: 0x204c0e70
[src/tokenizer.c:690] Token freed: 0x204c0e70 
[src/tokenizer.c:686] Token text freed: 0x204c0fb0
[src/tokenizer.c:690] Token freed: 0x204c0fb0 
[src/tokenizer.c:686] Token text freed: 0x204c0fd0
[src/tokenizer.c:690] Token freed: 0x204c0fd0 
[src/tokenizer.c:686] Token text freed: 0x204c1070
[src/tokenizer.c:690] Token freed: 0x204c1070 
[src/tokenizer.c:686] Token text freed: 0x204c1110
[src/tokenizer.c:690] Token freed: 0x204c1110 
[src/tokenizer.c:686] Token text freed: 0x204c1290
[src/tokenizer.c:690] Token freed: 0x204c1290 
[src/tokenizer.c:686] Token text freed: 0x204c12b0
[src/tokenizer.c:690] Token freed: 0x204c12b0 
[src/tokenizer.c:686] Token text freed: 0x204c1390
[src/tokenizer.c:690] Token freed: 0x204c1390 
[src/tokenizer.c:686] Token text freed: 0x204c1430
[src/tokenizer.c:690] Token freed: 0x204c1430 
[src/tokenizer.c:686] Token text freed: 0x204c15b0
[src/tokenizer.c:690] Token freed: 0x204c15b0 
[src/tokenizer.c:686] Token text freed: 0x204c15f0
[src/tokenizer.c:690] Token freed: 0x204c15f0 
[src/tokenizer.c:676] Token created: 0x204c1390, text: c
[src/tokenizer.c:676] Token created: 0x204c3930, text: a
[src/tokenizer.c:676] Token created: 0x204c1dc0, text: t
[src/tokenizer.c:676] Token created: 0x204c5be0, text: 
[src/tokenizer.c:676] Token created: 0x204bfa00, text: d
[src/tokenizer.c:676] Token created: 0x204c50a0, text: o
[src/tokenizer.c:676] Token created: 0x204bcc00, text: g
[src/tokenizer.c:676] Token created: 0x204c5260, text: 
[src/tokenizer.c:676] Token created: 0x204c1070, text: b
[src/tokenizer.c:676] Token created: 0x204be6c0, text: i
[src/tokenizer.c:676] Token created: 0x204c5c00, text: r
[src/tokenizer.c:676] Token created: 0x204c5420, text: d
[src/tokenizer.c:676] Token created: 0x204bf250, text: 
[src/tokenizer.c:676] Token created: 0x204bcd40, text: d
[src/tokenizer.c:676] Token created: 0x204ba2b0, text: o
[src/tokenizer.c:676] Token created: 0x204c1ca0, text: g
[src/tokenizer.c:676] Token created: 0x204c5500, text: 
[src/tokenizer.c:676] Token created: 0x204c5b60, text: c
[src/tokenizer.c:676] Token created: 0x204c3f10, text: a
[src/tokenizer.c:676] Token created: 0x204c5aa0, text: t
[src/tokenizer.c:676] Token created: 0x204c5660, text: 
[src/tokenizer.c:676] Token created: 0x204c4130, text: b
[src/tokenizer.c:676] Token created: 0x204c58c0, text: i
[src/tokenizer.c:676] Token created: 0x204c10f0, text: r
[src/tokenizer.c:676] Token created: 0x204c1110, text: d
[src/tokenizer.c:676] Token created: 0x204c0fb0, text: 

[src/tokenizer.c:676] Token created: 0x204c0fd0, text: 
[src/tokenizer.c:676] Token created: 0x204c0a30, text: a
[src/tokenizer.c:676] Token created: 0x204c0a50, text: p
[src/tokenizer.c:676] Token created: 0x204c08f0, text: p
[src/tokenizer.c:676] Token created: 0x204c3c50, text: l
[src/tokenizer.c:676] Token created: 0x204c1330, text: e
[src/tokenizer.c:676] Token created: 0x204c0ab0, text: 
[src/tokenizer.c:676] Token created: 0x204c5540, text: o
[src/tokenizer.c:676] Token created: 0x204c0950, text: r
[src/tokenizer.c:676] Token created: 0x204bfd20, text: a
[src/tokenizer.c:676] Token created: 0x204c1010, text: n
[src/tokenizer.c:676] Token created: 0x204c42d0, text: g
[src/tokenizer.c:676] Token created: 0x204c55a0, text: e
[src/tokenizer.c:676] Token created: 0x204c0f50, text: 
[src/tokenizer.c:676] Token created: 0x204bfae0, text: b
[src/tokenizer.c:676] Token created: 0x204c09d0, text: a
[src/tokenizer.c:676] Token created: 0x204c4ca0, text: n
[src/tokenizer.c:676] Token created: 0x204c0c90, text: a
[src/tokenizer.c:676] Token created: 0x204c52a0, text: n
[src/tokenizer.c:676] Token created: 0x204c3fd0, text: a
[src/tokenizer.c:676] Token created: 0x204c3cd0, text: 
[src/tokenizer.c:676] Token created: 0x204c3cf0, text: a
[src/tokenizer.c:676] Token created: 0x204c1530, text: p
[src/tokenizer.c:676] Token created: 0x204c3e50, text: p
[src/tokenizer.c:676] Token created: 0x204c51a0, text: l
[src/tokenizer.c:676] Token created: 0x204be670, text: e
[src/tokenizer.c:676] Token created: 0x204c2320, text: 
[src/tokenizer.c:676] Token created: 0x204c15b0, text: o
[src/tokenizer.c:676] Token created: 0x204c15f0, text: r
[src/tokenizer.c:676] Token created: 0x204bfda0, text: a
[src/tokenizer.c:676] Token created: 0x204bf9a0, text: n
[src/tokenizer.c:676] Token created: 0x204bf9e0, text: g
[src/tokenizer.c:676] Token created: 0x204c4090, text: e
[src/tokenizer.c:676] Token created: 0x204baf40, text: 
[src/tokenizer.c:676] Token created: 0x204beab0, text: b
[src/tokenizer.c:676] Token created: 0x204c4170, text: a
[src/tokenizer.c:676] Token created: 0x204c41b0, text: n
[src/tokenizer.c:676] Token created: 0x204c0590, text: a
[src/tokenizer.c:676] Token created: 0x204c5100, text: n
[src/tokenizer.c:676] Token created: 0x204c5140, text: a
[src/tokenizer.c:676] Token created: 0x204c3dd0, text: 

[src/tokenizer.c:676] Token created: 0x204c3a50, text: 
[src/tokenizer.c:676] Token created: 0x204c3a70, text: b
[src/tokenizer.c:676] Token created: 0x204c3a90, text: l
[src/tokenizer.c:676] Token created: 0x204c3f50, text: u
[src/tokenizer.c:676] Token created: 0x204c3f90, text: e
[src/tokenizer.c:676] Token created: 0x204c14b0, text: 
[src/tokenizer.c:676] Token created: 0x204c14d0, text: r
[src/tokenizer.c:676] Token created: 0x204bf5c0, text: e
[src/tokenizer.c:676] Token created: 0x204c4e20, text: d
[src/tokenizer.c:676] Token created: 0x204c4e60, text: 
[src/tokenizer.c:676] Token created: 0x204c1170, text: g
[src/tokenizer.c:676] Token created: 0x204c11b0, text: r
[src/tokenizer.c:676] Token created: 0x204c0b10, text: e
[src/tokenizer.c:676] Token created: 0x204c13f0, text: e
[src/tokenizer.c:676] Token created: 0x204c1430, text: n
[src/tokenizer.c:676] Token created: 0x204c6db0, text: 
[src/tokenizer.c:676] Token created: 0x204c6dd0, text: b
[src/tokenizer.c:676] Token created: 0x204c6c00, text: l
[src/tokenizer.c:676] Token created: 0x204c6ac0, text: u
[src/tokenizer.c:676] Token created: 0x204c6b00, text: e
[src/tokenizer.c:676] Token created: 0x204be520, text: 
[src/tokenizer.c:676] Token created: 0x204be540, text: r
[src/tokenizer.c:676] Token created: 0x204c0730, text: e
[src/tokenizer.c:676] Token created: 0x204c0770, text: d
[src/tokenizer.c:676] Token created: 0x204bfa20, text: 
[src/tokenizer.c:676] Token created: 0x204c4d20, text: g
[src/tokenizer.c:676] Token created: 0x204c4d60, text: r
[src/tokenizer.c:676] Token created: 0x204bcde0, text: e
[src/tokenizer.c:676] Token created: 0x204bce20, text: e
[src/tokenizer.c:676] Token created: 0x204c4230, text: n
[src/tokenizer.c:676] Token created: 0x204c4270, text: 

[src/tokenizer.c:676] Token created: 0x204c5740, text: 
[src/tokenizer.c:676] Token created: 0x204c5760, text: h
[src/tokenizer.c:676] Token created: 0x204c3ad0, text: a
[src/tokenizer.c:676] Token created: 0x204c3b10, text: p
[src/tokenizer.c:676] Token created: 0x204c3b30, text: p
[src/tokenizer.c:676] Token created: 0x204c38b0, text: y
[src/tokenizer.c:676] Token created: 0x204c38f0, text: 
[src/tokenizer.c:676] Token created: 0x204be460, text: s
[src/tokenizer.c:676] Token created: 0x204be480, text: a
[src/tokenizer.c:676] Token created: 0x204be4c0, text: d
[src/tokenizer.c:676] Token created: 0x204be5c0, text: 
[src/tokenizer.c:676] Token created: 0x204c3450, text: j
[src/tokenizer.c:676] Token created: 0x204c6520, text: o
[src/tokenizer.c:676] Token created: 0x204c6560, text: y
[src/tokenizer.c:676] Token created: 0x204beb10, text: f
[src/tokenizer.c:676] Token created: 0x204beb50, text: u
[src/tokenizer.c:676] Token created: 0x204beb90, text: l
[src/tokenizer.c:676] Token created: 0x204c0b90, text: 
[src/tokenizer.c:676] Token created: 0x204c0bb0, text: h
[src/tokenizer.c:676] Token created: 0x204c0bf0, text: a
[src/tokenizer.c:676] Token created: 0x204bf390, text: p
[src/tokenizer.c:676] Token created: 0x204bf3d0, text: p
[src/tokenizer.c:676] Token created: 0x204bfb40, text: y
[src/tokenizer.c:676] Token created: 0x204bfb80, text: 
[src/tokenizer.c:676] Token created: 0x204bfba0, text: s
[src/tokenizer.c:676] Token created: 0x204bfbc0, text: a
[src/tokenizer.c:676] Token created: 0x204badf0, text: d
[src/tokenizer.c:676] Token created: 0x204bae30, text: 
[src/tokenizer.c:676] Token created: 0x204c0850, text: j
[src/tokenizer.c:676] Token created: 0x204c57e0, text: o
[src/tokenizer.c:676] Token created: 0x204c5820, text: y
[src/tokenizer.c:676] Token created: 0x204c5320, text: f
[src/tokenizer.c:676] Token created: 0x204c5360, text: u
[src/tokenizer.c:676] Token created: 0x204c53a0, text: l
[src/tokenizer.c:676] Token created: 0x204c0d50, text: 

[src/tokenizer.c:676] Token created: 0x204c0d90, text: 
[src/tokenizer.c:676] Token created: 0x204c0db0, text: d
[src/tokenizer.c:676] Token created: 0x204c1f80, text: o
[src/tokenizer.c:676] Token created: 0x204c1fa0, text: g
[src/tokenizer.c:676] Token created: 0x204c1fc0, text: 
[src/tokenizer.c:676] Token created: 0x204c1250, text: a
[src/tokenizer.c:676] Token created: 0x204c1290, text: p
[src/tokenizer.c:676] Token created: 0x204c12d0, text: p
[src/tokenizer.c:676] Token created: 0x204bf2b0, text: l
[src/tokenizer.c:676] Token created: 0x204bf2f0, text: e
[src/tokenizer.c:676] Token created: 0x204bf330, text: 
[src/tokenizer.c:676] Token created: 0x204c3970, text: c
[src/tokenizer.c:676] Token created: 0x204c3990, text: a
[src/tokenizer.c:676] Token created: 0x204c39d0, text: t
[src/tokenizer.c:676] Token created: 0x204c3a10, text: 
[src/tokenizer.c:676] Token created: 0x204c20c0, text: o
[src/tokenizer.c:676] Token created: 0x204c1e00, text: r
[src/tokenizer.c:676] Token created: 0x204c1e40, text: a
[src/tokenizer.c:676] Token created: 0x204c1e80, text: n
[src/tokenizer.c:676] Token created: 0x204c4a20, text: g
[src/tokenizer.c:676] Token created: 0x204c4a60, text: e
[src/tokenizer.c:676] Token created: 0x204c4aa0, text: 
[src/tokenizer.c:676] Token created: 0x204c4ac0, text: b
[src/tokenizer.c:676] Token created: 0x204c63a0, text: i
[src/tokenizer.c:676] Token created: 0x204c63e0, text: r
[src/tokenizer.c:676] Token created: 0x204c6420, text: d
[src/tokenizer.c:676] Token created: 0x204c4750, text: 
[src/tokenizer.c:676] Token created: 0x204c47f0, text: b
[src/tokenizer.c:676] Token created: 0x204bfc20, text: a
[src/tokenizer.c:676] Token created: 0x204bfc60, text: n
[src/tokenizer.c:676] Token created: 0x204bfca0, text: a
[src/tokenizer.c:676] Token created: 0x204be360, text: n
[src/tokenizer.c:676] Token created: 0x204be3a0, text: a
[src/tokenizer.c:676] Token created: 0x204be3e0, text: 

[src/tokenizer.c:676] Token created: 0x204be420, text: 
Error while reading line in the textfile.
[src/tokenizer.c:505] Freeing the vocabulary at 809 
[src/tokenizer.c:686] Token text freed: 0x204c5160
[src/tokenizer.c:690] Token freed: 0x204c5160 
[src/tokenizer.c:505] Freeing the vocabulary at 1323 
[src/tokenizer.c:686] Token text freed: 0x204c4ba0
[src/tokenizer.c:690] Token freed: 0x204c4ba0 
[src/tokenizer.c:505] Freeing the vocabulary at 2749 
[src/tokenizer.c:686] Token text freed: 0x204c5e20
[src/tokenizer.c:690] Token freed: 0x204c5e20 
[src/tokenizer.c:505] Freeing the vocabulary at 4775 
[src/tokenizer.c:686] Token text freed: 0x204c53e0
[src/tokenizer.c:690] Token freed: 0x204c53e0 
[src/tokenizer.c:505] Freeing the vocabulary at 5192 
[src/tokenizer.c:686] Token text freed: 0x204c5240
[src/tokenizer.c:690] Token freed: 0x204c5240 
[src/tokenizer.c:505] Freeing the vocabulary at 8425 
[src/tokenizer.c:686] Token text freed: 0x204c4c60
[src/tokenizer.c:690] Token freed: 0x204c4c60 
[src/tokenizer.c:505] Freeing the vocabulary at 8453 
[src/tokenizer.c:686] Token text freed: 0x204c4c20
[src/tokenizer.c:690] Token freed: 0x204c4c20 
[src/tokenizer.c:505] Freeing the vocabulary at 9974 
[src/tokenizer.c:686] Token text freed: 0x204c3490
[src/tokenizer.c:690] Token freed: 0x204c3490 
[src/tokenizer.c:505] Freeing the vocabulary at 12605 
[src/tokenizer.c:686] Token text freed: 0x204c1590
[src/tokenizer.c:690] Token freed: 0x204c1590 
[src/tokenizer.c:505] Freeing the vocabulary at 13647 
[src/tokenizer.c:686] Token text freed: 0x204c43d0
[src/tokenizer.c:690] Token freed: 0x204c43d0 
[src/tokenizer.c:505] Freeing the vocabulary at 15412 
[src/tokenizer.c:686] Token text freed: 0x204c5640
[src/tokenizer.c:690] Token freed: 0x204c5640 
[src/tokenizer.c:505] Freeing the vocabulary at 18592 
[src/tokenizer.c:686] Token text freed: 0x204c57a0
[src/tokenizer.c:690] Token freed: 0x204c57a0 
[src/tokenizer.c:505] Freeing the vocabulary at 22787 
[src/tokenizer.c:686] Token text freed: 0x204c5cc0
[src/tokenizer.c:690] Token freed: 0x204c5cc0 
[src/tokenizer.c:505] Freeing the vocabulary at 30208 
[src/tokenizer.c:686] Token text freed: 0x204c4ce0
[src/tokenizer.c:690] Token freed: 0x204c4ce0 
[src/tokenizer.c:505] Freeing the vocabulary at 32654 
[src/tokenizer.c:686] Token text freed: 0x204bf410
[src/tokenizer.c:690] Token freed: 0x204bf410 
[src/tokenizer.c:505] Freeing the vocabulary at 40623 
[src/tokenizer.c:686] Token text freed: 0x204c58e0
[src/tokenizer.c:690] Token freed: 0x204c58e0 
[src/tokenizer.c:505] Freeing the vocabulary at 45852 
[src/tokenizer.c:686] Token text freed: 0x204c3b90
[src/tokenizer.c:690] Token freed: 0x204c3b90 
[src/tokenizer.c:505] Freeing the vocabulary at 47680 
[src/tokenizer.c:686] Token text freed: 0x204c5d40
[src/tokenizer.c:690] Token freed: 0x204c5d40 
[src/tokenizer.c:505] Freeing the vocabulary at 51547 
[src/tokenizer.c:686] Token text freed: 0x204c41d0
[src/tokenizer.c:690] Token freed: 0x204c41d0 
[src/tokenizer.c:505] Freeing the vocabulary at 52407 
[src/tokenizer.c:686] Token text freed: 0x204bf580
[src/tokenizer.c:690] Token freed: 0x204bf580 
[src/tokenizer.c:505] Freeing the vocabulary at 59989 
[src/tokenizer.c:686] Token text freed: 0x204c5960
[src/tokenizer.c:690] Token freed: 0x204c5960 
[src/tokenizer.c:505] Freeing the vocabulary at 70530 
[src/tokenizer.c:686] Token text freed: 0x204c5ca0
[src/tokenizer.c:690] Token freed: 0x204c5ca0 
[src/tokenizer.c:505] Freeing the vocabulary at 71771 
[src/tokenizer.c:686] Token text freed: 0x204c4310
[src/tokenizer.c:690] Token freed: 0x204c4310 
[src/tokenizer.c:505] Freeing the vocabulary at 77004 
[src/tokenizer.c:686] Token text freed: 0x204c0ad0
[src/tokenizer.c:690] Token freed: 0x204c0ad0 
[src/tokenizer.c:505] Freeing the vocabulary at 77541 
[src/tokenizer.c:686] Token text freed: 0x204c3d10
[src/tokenizer.c:690] Token freed: 0x204c3d10 
[src/tokenizer.c:505] Freeing the vocabulary at 80357 
[src/tokenizer.c:686] Token text freed: 0x204bf760
[src/tokenizer.c:690] Token freed: 0x204bf760 
[src/tokenizer.c:505] Freeing the vocabulary at 85943 
[src/tokenizer.c:686] Token text freed: 0x204c5d00
[src/tokenizer.c:690] Token freed: 0x204c5d00 
[src/tokenizer.c:505] Freeing the vocabulary at 86436 
[src/tokenizer.c:686] Token text freed: 0x204c5280
[src/tokenizer.c:690] Token freed: 0x204c5280 
[src/tokenizer.c:505] Freeing the vocabulary at 91146 
[src/tokenizer.c:686] Token text freed: 0x204c3850
[src/tokenizer.c:690] Token freed: 0x204c3850 
[src/tokenizer.c:505] Freeing the vocabulary at 92358 
[src/tokenizer.c:686] Token text freed: 0x204c5200
[src/tokenizer.c:690] Token freed: 0x204c5200 
[src/tokenizer.c:505] Freeing the vocabulary at 97491 
[src/tokenizer.c:686] Token text freed: 0x204c5300
[src/tokenizer.c:690] Token freed: 0x204c5300 
[src/tokenizer.c:505] Freeing the vocabulary at 100726 
[src/tokenizer.c:686] Token text freed: 0x204c5d80
[src/tokenizer.c:690] Token freed: 0x204c5d80 
[src/tokenizer.c:505] Freeing the vocabulary at 100962 
[src/tokenizer.c:686] Token text freed: 0x204c5dd0
[src/tokenizer.c:690] Token freed: 0x204c5dd0 
[src/tokenizer.c:505] Freeing the vocabulary at 101790 
[src/tokenizer.c:686] Token text freed: 0x204c2240
[src/tokenizer.c:690] Token freed: 0x204c2240 
[src/tokenizer.c:505] Freeing the vocabulary at 101824 
[src/tokenizer.c:686] Token text freed: 0x204c3fb0
[src/tokenizer.c:690] Token freed: 0x204c3fb0 
[src/tokenizer.c:505] Freeing the vocabulary at 108056 
[src/tokenizer.c:686] Token text freed: 0x204c5a80
[src/tokenizer.c:690] Token freed: 0x204c5a80 
[src/tokenizer.c:505] Freeing the vocabulary at 118919 
[src/tokenizer.c:686] Token text freed: 0x204c5680
[src/tokenizer.c:690] Token freed: 0x204c5680 
[src/tokenizer.c:505] Freeing the vocabulary at 122893 
[src/tokenizer.c:686] Token text freed: 0x204c2100
[src/tokenizer.c:690] Token freed: 0x204c2100 
[src/tokenizer.c:505] Freeing the vocabulary at 123071 
[src/tokenizer.c:686] Token text freed: 0x204c5c80
[src/tokenizer.c:690] Token freed: 0x204c5c80 
[src/tokenizer.c:505] Freeing the vocabulary at 123075 
[src/tokenizer.c:686] Token text freed: 0x204c5c60
[src/tokenizer.c:690] Token freed: 0x204c5c60 
[src/tokenizer.c:505] Freeing the vocabulary at 124757 
[src/tokenizer.c:686] Token text freed: 0x204c4e00
[src/tokenizer.c:690] Token freed: 0x204c4e00 
[src/tokenizer.c:505] Freeing the vocabulary at 126710 
[src/tokenizer.c:686] Token text freed: 0x204c5600
[src/tokenizer.c:690] Token freed: 0x204c5600 
[src/tokenizer.c:505] Freeing the vocabulary at 127044 
[src/tokenizer.c:686] Token text freed: 0x204c4e80
[src/tokenizer.c:690] Token freed: 0x204c4e80 
[src/tokenizer.c:505] Freeing the vocabulary at 130190 
[src/tokenizer.c:686] Token text freed: 0x204c54e0
[src/tokenizer.c:690] Token freed: 0x204c54e0 
[src/tokenizer.c:505] Freeing the vocabulary at 131673 
[src/tokenizer.c:686] Token text freed: 0x204c5580
[src/tokenizer.c:690] Token freed: 0x204c5580 
[src/tokenizer.c:505] Freeing the vocabulary at 134850 
[src/tokenizer.c:686] Token text freed: 0x204c40d0
[src/tokenizer.c:690] Token freed: 0x204c40d0 
[src/tokenizer.c:505] Freeing the vocabulary at 141110 
[src/tokenizer.c:686] Token text freed: 0x204c3bf0
[src/tokenizer.c:690] Token freed: 0x204c3bf0 
[src/tokenizer.c:505] Freeing the vocabulary at 144817 
[src/tokenizer.c:686] Token text freed: 0x204c3c90
[src/tokenizer.c:690] Token freed: 0x204c3c90 
[src/tokenizer.c:505] Freeing the vocabulary at 153909 
[src/tokenizer.c:686] Token text freed: 0x204c21c0
[src/tokenizer.c:690] Token freed: 0x204c21c0 
[src/tokenizer.c:505] Freeing the vocabulary at 159643 
[src/tokenizer.c:686] Token text freed: 0x204c21e0
[src/tokenizer.c:690] Token freed: 0x204c21e0 
[src/tokenizer.c:505] Freeing the vocabulary at 160404 
[src/tokenizer.c:686] Token text freed: 0x204c5c40
[src/tokenizer.c:690] Token freed: 0x204c5c40 
[src/tokenizer.c:505] Freeing the vocabulary at 160405 
[src/tokenizer.c:686] Token text freed: 0x204c1ec0
[src/tokenizer.c:690] Token freed: 0x204c1ec0 
[src/tokenizer.c:505] Freeing the vocabulary at 162267 
[src/tokenizer.c:686] Token text freed: 0x204c5480
[src/tokenizer.c:690] Token freed: 0x204c5480 
[src/tokenizer.c:505] Freeing the vocabulary at 164625 
[src/tokenizer.c:686] Token text freed: 0x204c5a60
[src/tokenizer.c:690] Token freed: 0x204c5a60 
[src/tokenizer.c:505] Freeing the vocabulary at 170178 
[src/tokenizer.c:686] Token text freed: 0x204c3c10
[src/tokenizer.c:690] Token freed: 0x204c3c10 
[src/tokenizer.c:505] Freeing the vocabulary at 170209 
[src/tokenizer.c:686] Token text freed: 0x204c05d0
[src/tokenizer.c:690] Token freed: 0x204c05d0 
[src/tokenizer.c:505] Freeing the vocabulary at 172158 
[src/tokenizer.c:686] Token text freed: 0x204c1550
[src/tokenizer.c:690] Token freed: 0x204c1550 
[src/tokenizer.c:505] Freeing the vocabulary at 183299 
[src/tokenizer.c:686] Token text freed: 0x204c5b80
[src/tokenizer.c:690] Token freed: 0x204c5b80 
[src/tokenizer.c:505] Freeing the vocabulary at 185916 
[src/tokenizer.c:686] Token text freed: 0x204c1370
[src/tokenizer.c:690] Token freed: 0x204c1370 
[src/tokenizer.c:505] Freeing the vocabulary at 189762 
[src/tokenizer.c:686] Token text freed: 0x204c4470
[src/tokenizer.c:690] Token freed: 0x204c4470 
[src/tokenizer.c:514] Freeing the Vocabulary itself 0x7f7b7d479010
[src/tokenizer.c:686] Token text freed: 0x204c1390
[src/tokenizer.c:690] Token freed: 0x204c1390 
[src/tokenizer.c:686] Token text freed: 0x204c3930
[src/tokenizer.c:690] Token freed: 0x204c3930 
[src/tokenizer.c:686] Token text freed: 0x204c1dc0
[src/tokenizer.c:690] Token freed: 0x204c1dc0 
[src/tokenizer.c:686] Token text freed: 0x204c5be0
[src/tokenizer.c:690] Token freed: 0x204c5be0 
[src/tokenizer.c:686] Token text freed: 0x204bfa00
[src/tokenizer.c:690] Token freed: 0x204bfa00 
[src/tokenizer.c:686] Token text freed: 0x204c50a0
[src/tokenizer.c:690] Token freed: 0x204c50a0 
[src/tokenizer.c:686] Token text freed: 0x204bcc00
[src/tokenizer.c:690] Token freed: 0x204bcc00 
[src/tokenizer.c:686] Token text freed: 0x204c5260
[src/tokenizer.c:690] Token freed: 0x204c5260 
[src/tokenizer.c:686] Token text freed: 0x204c1070
[src/tokenizer.c:690] Token freed: 0x204c1070 
[src/tokenizer.c:686] Token text freed: 0x204be6c0
[src/tokenizer.c:690] Token freed: 0x204be6c0 
[src/tokenizer.c:686] Token text freed: 0x204c5c00
[src/tokenizer.c:690] Token freed: 0x204c5c00 
[src/tokenizer.c:686] Token text freed: 0x204c5420
[src/tokenizer.c:690] Token freed: 0x204c5420 
[src/tokenizer.c:686] Token text freed: 0x204bf250
[src/tokenizer.c:690] Token freed: 0x204bf250 
[src/tokenizer.c:686] Token text freed: 0x204bcd40
[src/tokenizer.c:690] Token freed: 0x204bcd40 
[src/tokenizer.c:686] Token text freed: 0x204ba2b0
[src/tokenizer.c:690] Token freed: 0x204ba2b0 
[src/tokenizer.c:686] Token text freed: 0x204c1ca0
[src/tokenizer.c:690] Token freed: 0x204c1ca0 
[src/tokenizer.c:686] Token text freed: 0x204c5500
[src/tokenizer.c:690] Token freed: 0x204c5500 
[src/tokenizer.c:686] Token text freed: 0x204c5b60
[src/tokenizer.c:690] Token freed: 0x204c5b60 
[src/tokenizer.c:686] Token text freed: 0x204c3f10
[src/tokenizer.c:690] Token freed: 0x204c3f10 
[src/tokenizer.c:686] Token text freed: 0x204c5aa0
[src/tokenizer.c:690] Token freed: 0x204c5aa0 
[src/tokenizer.c:686] Token text freed: 0x204c5660
[src/tokenizer.c:690] Token freed: 0x204c5660 
[src/tokenizer.c:686] Token text freed: 0x204c4130
[src/tokenizer.c:690] Token freed: 0x204c4130 
[src/tokenizer.c:686] Token text freed: 0x204c58c0
[src/tokenizer.c:690] Token freed: 0x204c58c0 
[src/tokenizer.c:686] Token text freed: 0x204c10f0
[src/tokenizer.c:690] Token freed: 0x204c10f0 
[src/tokenizer.c:686] Token text freed: 0x204c1110
[src/tokenizer.c:690] Token freed: 0x204c1110 
[src/tokenizer.c:686] Token text freed: 0x204c0fb0
[src/tokenizer.c:690] Token freed: 0x204c0fb0 
[src/tokenizer.c:686] Token text freed: 0x204c0fd0
[src/tokenizer.c:690] Token freed: 0x204c0fd0 
[src/tokenizer.c:686] Token text freed: 0x204c0a30
[src/tokenizer.c:690] Token freed: 0x204c0a30 
[src/tokenizer.c:686] Token text freed: 0x204c0a50
[src/tokenizer.c:690] Token freed: 0x204c0a50 
[src/tokenizer.c:686] Token text freed: 0x204c08f0
[src/tokenizer.c:690] Token freed: 0x204c08f0 
[src/tokenizer.c:686] Token text freed: 0x204c3c50
[src/tokenizer.c:690] Token freed: 0x204c3c50 
[src/tokenizer.c:686] Token text freed: 0x204c1330
[src/tokenizer.c:690] Token freed: 0x204c1330 
[src/tokenizer.c:686] Token text freed: 0x204c0ab0
[src/tokenizer.c:690] Token freed: 0x204c0ab0 
[src/tokenizer.c:686] Token text freed: 0x204c5540
[src/tokenizer.c:690] Token freed: 0x204c5540 
[src/tokenizer.c:686] Token text freed: 0x204c0950
[src/tokenizer.c:690] Token freed: 0x204c0950 
[src/tokenizer.c:686] Token text freed: 0x204bfd20
[src/tokenizer.c:690] Token freed: 0x204bfd20 
[src/tokenizer.c:686] Token text freed: 0x204c1010
[src/tokenizer.c:690] Token freed: 0x204c1010 
[src/tokenizer.c:686] Token text freed: 0x204c42d0
[src/tokenizer.c:690] Token freed: 0x204c42d0 
[src/tokenizer.c:686] Token text freed: 0x204c55a0
[src/tokenizer.c:690] Token freed: 0x204c55a0 
[src/tokenizer.c:686] Token text freed: 0x204c0f50
[src/tokenizer.c:690] Token freed: 0x204c0f50 
[src/tokenizer.c:686] Token text freed: 0x204bfae0
[src/tokenizer.c:690] Token freed: 0x204bfae0 
[src/tokenizer.c:686] Token text freed: 0x204c09d0
[src/tokenizer.c:690] Token freed: 0x204c09d0 
[src/tokenizer.c:686] Token text freed: 0x204c4ca0
[src/tokenizer.c:690] Token freed: 0x204c4ca0 
[src/tokenizer.c:686] Token text freed: 0x204c0c90
[src/tokenizer.c:690] Token freed: 0x204c0c90 
[src/tokenizer.c:686] Token text freed: 0x204c52a0
[src/tokenizer.c:690] Token freed: 0x204c52a0 
[src/tokenizer.c:686] Token text freed: 0x204c3fd0
[src/tokenizer.c:690] Token freed: 0x204c3fd0 
[src/tokenizer.c:686] Token text freed: 0x204c3cd0
[src/tokenizer.c:690] Token freed: 0x204c3cd0 
[src/tokenizer.c:686] Token text freed: 0x204c3cf0
[src/tokenizer.c:690] Token freed: 0x204c3cf0 
[src/tokenizer.c:686] Token text freed: 0x204c1530
[src/tokenizer.c:690] Token freed: 0x204c1530 
[src/tokenizer.c:686] Token text freed: 0x204c3e50
[src/tokenizer.c:690] Token freed: 0x204c3e50 
[src/tokenizer.c:686] Token text freed: 0x204c51a0
[src/tokenizer.c:690] Token freed: 0x204c51a0 
[src/tokenizer.c:686] Token text freed: 0x204be670
[src/tokenizer.c:690] Token freed: 0x204be670 
[src/tokenizer.c:686] Token text freed: 0x204c2320
[src/tokenizer.c:690] Token freed: 0x204c2320 
[src/tokenizer.c:686] Token text freed: 0x204c15b0
[src/tokenizer.c:690] Token freed: 0x204c15b0 
[src/tokenizer.c:686] Token text freed: 0x204c15f0
[src/tokenizer.c:690] Token freed: 0x204c15f0 
[src/tokenizer.c:686] Token text freed: 0x204bfda0
[src/tokenizer.c:690] Token freed: 0x204bfda0 
[src/tokenizer.c:686] Token text freed: 0x204bf9a0
[src/tokenizer.c:690] Token freed: 0x204bf9a0 
[src/tokenizer.c:686] Token text freed: 0x204bf9e0
[src/tokenizer.c:690] Token freed: 0x204bf9e0 
[src/tokenizer.c:686] Token text freed: 0x204c4090
[src/tokenizer.c:690] Token freed: 0x204c4090 
[src/tokenizer.c:686] Token text freed: 0x204baf40
[src/tokenizer.c:690] Token freed: 0x204baf40 
[src/tokenizer.c:686] Token text freed: 0x204beab0
[src/tokenizer.c:690] Token freed: 0x204beab0 
[src/tokenizer.c:686] Token text freed: 0x204c4170
[src/tokenizer.c:690] Token freed: 0x204c4170 
[src/tokenizer.c:686] Token text freed: 0x204c41b0
[src/tokenizer.c:690] Token freed: 0x204c41b0 
[src/tokenizer.c:686] Token text freed: 0x204c0590
[src/tokenizer.c:690] Token freed: 0x204c0590 
[src/tokenizer.c:686] Token text freed: 0x204c5100
[src/tokenizer.c:690] Token freed: 0x204c5100 
[src/tokenizer.c:686] Token text freed: 0x204c5140
[src/tokenizer.c:690] Token freed: 0x204c5140 
[src/tokenizer.c:686] Token text freed: 0x204c3dd0
[src/tokenizer.c:690] Token freed: 0x204c3dd0 
[src/tokenizer.c:686] Token text freed: 0x204c3a50
[src/tokenizer.c:690] Token freed: 0x204c3a50 
[src/tokenizer.c:686] Token text freed: 0x204c3a70
[src/tokenizer.c:690] Token freed: 0x204c3a70 
[src/tokenizer.c:686] Token text freed: 0x204c3a90
[src/tokenizer.c:690] Token freed: 0x204c3a90 
[src/tokenizer.c:686] Token text freed: 0x204c3f50
[src/tokenizer.c:690] Token freed: 0x204c3f50 
[src/tokenizer.c:686] Token text freed: 0x204c3f90
[src/tokenizer.c:690] Token freed: 0x204c3f90 
[src/tokenizer.c:686] Token text freed: 0x204c14b0
[src/tokenizer.c:690] Token freed: 0x204c14b0 
[src/tokenizer.c:686] Token text freed: 0x204c14d0
[src/tokenizer.c:690] Token freed: 0x204c14d0 
[src/tokenizer.c:686] Token text freed: 0x204bf5c0
[src/tokenizer.c:690] Token freed: 0x204bf5c0 
[src/tokenizer.c:686] Token text freed: 0x204c4e20
[src/tokenizer.c:690] Token freed: 0x204c4e20 
[src/tokenizer.c:686] Token text freed: 0x204c4e60
[src/tokenizer.c:690] Token freed: 0x204c4e60 
[src/tokenizer.c:686] Token text freed: 0x204c1170
[src/tokenizer.c:690] Token freed: 0x204c1170 
[src/tokenizer.c:686] Token text freed: 0x204c11b0
[src/tokenizer.c:690] Token freed: 0x204c11b0 
[src/tokenizer.c:686] Token text freed: 0x204c0b10
[src/tokenizer.c:690] Token freed: 0x204c0b10 
[src/tokenizer.c:686] Token text freed: 0x204c13f0
[src/tokenizer.c:690] Token freed: 0x204c13f0 
[src/tokenizer.c:686] Token text freed: 0x204c1430
[src/tokenizer.c:690] Token freed: 0x204c1430 
[src/tokenizer.c:686] Token text freed: 0x204c6db0
[src/tokenizer.c:690] Token freed: 0x204c6db0 
[src/tokenizer.c:686] Token text freed: 0x204c6dd0
[src/tokenizer.c:690] Token freed: 0x204c6dd0 
[src/tokenizer.c:686] Token text freed: 0x204c6c00
[src/tokenizer.c:690] Token freed: 0x204c6c00 
[src/tokenizer.c:686] Token text freed: 0x204c6ac0
[src/tokenizer.c:690] Token freed: 0x204c6ac0 
[src/tokenizer.c:686] Token text freed: 0x204c6b00
[src/tokenizer.c:690] Token freed: 0x204c6b00 
[src/tokenizer.c:686] Token text freed: 0x204be520
[src/tokenizer.c:690] Token freed: 0x204be520 
[src/tokenizer.c:686] Token text freed: 0x204be540
[src/tokenizer.c:690] Token freed: 0x204be540 
[src/tokenizer.c:686] Token text freed: 0x204c0730
[src/tokenizer.c:690] Token freed: 0x204c0730 
[src/tokenizer.c:686] Token text freed: 0x204c0770
[src/tokenizer.c:690] Token freed: 0x204c0770 
[src/tokenizer.c:686] Token text freed: 0x204bfa20
[src/tokenizer.c:690] Token freed: 0x204bfa20 
[src/tokenizer.c:686] Token text freed: 0x204c4d20
[src/tokenizer.c:690] Token freed: 0x204c4d20 
[src/tokenizer.c:686] Token text freed: 0x204c4d60
[src/tokenizer.c:690] Token freed: 0x204c4d60 
[src/tokenizer.c:686] Token text freed: 0x204bcde0
[src/tokenizer.c:690] Token freed: 0x204bcde0 
[src/tokenizer.c:686] Token text freed: 0x204bce20
[src/tokenizer.c:690] Token freed: 0x204bce20 
[src/tokenizer.c:686] Token text freed: 0x204c4230
[src/tokenizer.c:690] Token freed: 0x204c4230 
[src/tokenizer.c:686] Token text freed: 0x204c4270
[src/tokenizer.c:690] Token freed: 0x204c4270 
[src/tokenizer.c:686] Token text freed: 0x204c5740
[src/tokenizer.c:690] Token freed: 0x204c5740 
[src/tokenizer.c:686] Token text freed: 0x204c5760
[src/tokenizer.c:690] Token freed: 0x204c5760 
[src/tokenizer.c:686] Token text freed: 0x204c3ad0
[src/tokenizer.c:690] Token freed: 0x204c3ad0 
[src/tokenizer.c:686] Token text freed: 0x204c3b10
[src/tokenizer.c:690] Token freed: 0x204c3b10 
[src/tokenizer.c:686] Token text freed: 0x204c3b30
[src/tokenizer.c:690] Token freed: 0x204c3b30 
[src/tokenizer.c:686] Token text freed: 0x204c38b0
[src/tokenizer.c:690] Token freed: 0x204c38b0 
[src/tokenizer.c:686] Token text freed: 0x204c38f0
[src/tokenizer.c:690] Token freed: 0x204c38f0 
[src/tokenizer.c:686] Token text freed: 0x204be460
[src/tokenizer.c:690] Token freed: 0x204be460 
[src/tokenizer.c:686] Token text freed: 0x204be480
[src/tokenizer.c:690] Token freed: 0x204be480 
[src/tokenizer.c:686] Token text freed: 0x204be4c0
[src/tokenizer.c:690] Token freed: 0x204be4c0 
[src/tokenizer.c:686] Token text freed: 0x204be5c0
[src/tokenizer.c:690] Token freed: 0x204be5c0 
[src/tokenizer.c:686] Token text freed: 0x204c3450
[src/tokenizer.c:690] Token freed: 0x204c3450 
[src/tokenizer.c:686] Token text freed: 0x204c6520
[src/tokenizer.c:690] Token freed: 0x204c6520 
[src/tokenizer.c:686] Token text freed: 0x204c6560
[src/tokenizer.c:690] Token freed: 0x204c6560 
[src/tokenizer.c:686] Token text freed: 0x204beb10
[src/tokenizer.c:690] Token freed: 0x204beb10 
[src/tokenizer.c:686] Token text freed: 0x204beb50
[src/tokenizer.c:690] Token freed: 0x204beb50 
[src/tokenizer.c:686] Token text freed: 0x204beb90
[src/tokenizer.c:690] Token freed: 0x204beb90 
[src/tokenizer.c:686] Token text freed: 0x204c0b90
[src/tokenizer.c:690] Token freed: 0x204c0b90 
[src/tokenizer.c:686] Token text freed: 0x204c0bb0
[src/tokenizer.c:690] Token freed: 0x204c0bb0 
[src/tokenizer.c:686] Token text freed: 0x204c0bf0
[src/tokenizer.c:690] Token freed: 0x204c0bf0 
[src/tokenizer.c:686] Token text freed: 0x204bf390
[src/tokenizer.c:690] Token freed: 0x204bf390 
[src/tokenizer.c:686] Token text freed: 0x204bf3d0
[src/tokenizer.c:690] Token freed: 0x204bf3d0 
[src/tokenizer.c:686] Token text freed: 0x204bfb40
[src/tokenizer.c:690] Token freed: 0x204bfb40 
[src/tokenizer.c:686] Token text freed: 0x204bfb80
[src/tokenizer.c:690] Token freed: 0x204bfb80 
[src/tokenizer.c:686] Token text freed: 0x204bfba0
[src/tokenizer.c:690] Token freed: 0x204bfba0 
[src/tokenizer.c:686] Token text freed: 0x204bfbc0
[src/tokenizer.c:690] Token freed: 0x204bfbc0 
[src/tokenizer.c:686] Token text freed: 0x204badf0
[src/tokenizer.c:690] Token freed: 0x204badf0 
[src/tokenizer.c:686] Token text freed: 0x204bae30
[src/tokenizer.c:690] Token freed: 0x204bae30 
[src/tokenizer.c:686] Token text freed: 0x204c0850
[src/tokenizer.c:690] Token freed: 0x204c0850 
[src/tokenizer.c:686] Token text freed: 0x204c57e0
[src/tokenizer.c:690] Token freed: 0x204c57e0 
[src/tokenizer.c:686] Token text freed: 0x204c5820
[src/tokenizer.c:690] Token freed: 0x204c5820 
[src/tokenizer.c:686] Token text freed: 0x204c5320
[src/tokenizer.c:690] Token freed: 0x204c5320 
[src/tokenizer.c:686] Token text freed: 0x204c5360
[src/tokenizer.c:690] Token freed: 0x204c5360 
[src/tokenizer.c:686] Token text freed: 0x204c53a0
[src/tokenizer.c:690] Token freed: 0x204c53a0 
[src/tokenizer.c:686] Token text freed: 0x204c0d50
[src/tokenizer.c:690] Token freed: 0x204c0d50 
[src/tokenizer.c:686] Token text freed: 0x204c0d90
[src/tokenizer.c:690] Token freed: 0x204c0d90 
[src/tokenizer.c:686] Token text freed: 0x204c0db0
[src/tokenizer.c:690] Token freed: 0x204c0db0 
[src/tokenizer.c:686] Token text freed: 0x204c1f80
[src/tokenizer.c:690] Token freed: 0x204c1f80 
[src/tokenizer.c:686] Token text freed: 0x204c1fa0
[src/tokenizer.c:690] Token freed: 0x204c1fa0 
[src/tokenizer.c:686] Token text freed: 0x204c1fc0
[src/tokenizer.c:690] Token freed: 0x204c1fc0 
[src/tokenizer.c:686] Token text freed: 0x204c1250
[src/tokenizer.c:690] Token freed: 0x204c1250 
[src/tokenizer.c:686] Token text freed: 0x204c1290
[src/tokenizer.c:690] Token freed: 0x204c1290 
[src/tokenizer.c:686] Token text freed: 0x204c12d0
[src/tokenizer.c:690] Token freed: 0x204c12d0 
[src/tokenizer.c:686] Token text freed: 0x204bf2b0
[src/tokenizer.c:690] Token freed: 0x204bf2b0 
[src/tokenizer.c:686] Token text freed: 0x204bf2f0
[src/tokenizer.c:690] Token freed: 0x204bf2f0 
[src/tokenizer.c:686] Token text freed: 0x204bf330
[src/tokenizer.c:690] Token freed: 0x204bf330 
[src/tokenizer.c:686] Token text freed: 0x204c3970
[src/tokenizer.c:690] Token freed: 0x204c3970 
[src/tokenizer.c:686] Token text freed: 0x204c3990
[src/tokenizer.c:690] Token freed: 0x204c3990 
[src/tokenizer.c:686] Token text freed: 0x204c39d0
[src/tokenizer.c:690] Token freed: 0x204c39d0 
[src/tokenizer.c:686] Token text freed: 0x204c3a10
[src/tokenizer.c:690] Token freed: 0x204c3a10 
[src/tokenizer.c:686] Token text freed: 0x204c20c0
[src/tokenizer.c:690] Token freed: 0x204c20c0 
[src/tokenizer.c:686] Token text freed: 0x204c1e00
[src/tokenizer.c:690] Token freed: 0x204c1e00 
[src/tokenizer.c:686] Token text freed: 0x204c1e40
[src/tokenizer.c:690] Token freed: 0x204c1e40 
[src/tokenizer.c:686] Token text freed: 0x204c1e80
[src/tokenizer.c:690] Token freed: 0x204c1e80 
[src/tokenizer.c:686] Token text freed: 0x204c4a20
[src/tokenizer.c:690] Token freed: 0x204c4a20 
[src/tokenizer.c:686] Token text freed: 0x204c4a60
[src/tokenizer.c:690] Token freed: 0x204c4a60 
[src/tokenizer.c:686] Token text freed: 0x204c4aa0
[src/tokenizer.c:690] Token freed: 0x204c4aa0 
[src/tokenizer.c:686] Token text freed: 0x204c4ac0
[src/tokenizer.c:690] Token freed: 0x204c4ac0 
[src/tokenizer.c:686] Token text freed: 0x204c63a0
[src/tokenizer.c:690] Token freed: 0x204c63a0 
[src/tokenizer.c:686] Token text freed: 0x204c63e0
[src/tokenizer.c:690] Token freed: 0x204c63e0 
[src/tokenizer.c:686] Token text freed: 0x204c6420
[src/tokenizer.c:690] Token freed: 0x204c6420 
[src/tokenizer.c:686] Token text freed: 0x204c4750
[src/tokenizer.c:690] Token freed: 0x204c4750 
[src/tokenizer.c:686] Token text freed: 0x204c47f0
[src/tokenizer.c:690] Token freed: 0x204c47f0 
[src/tokenizer.c:686] Token text freed: 0x204bfc20
[src/tokenizer.c:690] Token freed: 0x204bfc20 
[src/tokenizer.c:686] Token text freed: 0x204bfc60
[src/tokenizer.c:690] Token freed: 0x204bfc60 
[src/tokenizer.c:686] Token text freed: 0x204bfca0
[src/tokenizer.c:690] Token freed: 0x204bfca0 
[src/tokenizer.c:686] Token text freed: 0x204be360
[src/tokenizer.c:690] Token freed: 0x204be360 
[src/tokenizer.c:686] Token text freed: 0x204be3a0
[src/tokenizer.c:690] Token freed: 0x204be3a0 
[src/tokenizer.c:686] Token text freed: 0x204be3e0
[src/tokenizer.c:690] Token freed: 0x204be3e0 
[src/tokenizer.c:686] Token text freed: 0x204be420
[src/tokenizer.c:690] Token freed: 0x204be420 
Running Dataset Tests...
Running Hash Table Tests...
Running Free Tokenizer Memory Tests....

Running BPE Tests...

Edge Case 1: Empty Dataset
Vocabulary (size: 0, max size: 10):
BPE complete. Final vocabulary size: 6

Edge Case 2: Single-line Dataset
Vocabulary (size: 6, max size: 10):
  Token 5: a (freq: 1)
  Token 0:  (freq: 4)
  Token 6: b (freq: 1)
  Token 4: c (freq: 1)
  Token 7: d (freq: 1)
  Token 3: 
 (freq: 1)
Completed 0 merges, vocabulary size: 23
BPE complete. Final vocabulary size: 60

General Case: Larger Dataset with Varied Patterns
Vocabulary (size: 60, max size: 200000):
  Token 160404: c (freq: 1)
  Token 123075: a (freq: 22)
  Token 123071: t (freq: 3)
  Token 70530:  (freq: 30)
  Token 22787: d (freq: 10)
  Token 85943: o (freq: 8)
  Token 47680: g (freq: 8)
  Token 100726: b (freq: 8)
  Token 100962: i (freq: 3)
  Token 2749: r (freq: 10)
  Token 160405: c (freq: 2)
  Token 122893: 
 (freq: 5)
  Token 153909: p (freq: 10)
  Token 101790: l (freq: 7)
  Token 159643: e (freq: 14)
  Token 9974: n (freq: 11)
  Token 77541: u (freq: 4)
  Token 189762: h (freq: 2)
  Token 1323: y (freq: 4)
  Token 8453: s (freq: 2)
  Token 30208: j (freq: 2)
  Token 124757: f (freq: 2)
  Token 91146: do (freq: 1)
  Token 809: ra (freq: 1)
  Token 45852: an (freq: 1)
  Token 59989: fu (freq: 1)
  Token 130190: py (freq: 1)
  Token 164625: ue (freq: 1)
  Token 97491: le (freq: 1)
  Token 92358: bi (freq: 1)
  Token 8425: at (freq: 1)
  Token 13647: re (freq: 1)
  Token 4775: anan (freq: 3)
  Token 101824: ge (freq: 1)
  Token 131673: ap (freq: 1)
  Token 118919: bl (freq: 1)
  Token 141110: banan (freq: 3)
  Token 40623: blue (freq: 2)
  Token 172158: ad (freq: 1)
  Token 162267: bir (freq: 3)
  Token 127044: appy (freq: 2)
  Token 134850: ful (freq: 2)
  Token 126710: banana (freq: 3)
  Token 15412: nge (freq: 3)
  Token 18592: jo (freq: 1)
  Token 170209: bird (freq: 3)
  Token 71771: ple (freq: 3)
  Token 108056: dog (freq: 3)
  Token 52407: yful (freq: 2)
  Token 170178: range (freq: 3)
  Token 183299: en (freq: 1)
  Token 77004: joyful (freq: 2)
  Token 32654: apple (freq: 3)
  Token 185916: happy (freq: 2)
  Token 51547: gre (freq: 2)
  Token 86436: red (freq: 2)
  Token 5192: orange (freq: 3)
  Token 80357: sad (freq: 2)
  Token 12605: cat (freq: 3)
  Token 144817: green (freq: 2)

Final Tokenized Dataset:
c a t  d o g  b i r d  d o g  c a t  b i r d 
  a p p l e  o r a n g e  b a n a n a  a p p l e  o r a n g e  b a n a n a 
  b l u e  r e d  g r e e n  b l u e  r e d  g r e e n 
  h a p p y  s a d  j o y f u l  h a p p y  s a d  j o y f u l 
  d o g  a p p l e  c a t  o r a n g e  b i r d  b a n a n a 
  
BPE Tests Completed.
All tests completed.
